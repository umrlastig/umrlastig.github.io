<!DOCTYPE html><html lang="en-US"><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><meta name="generator" content="Gatsby 5.15.0"/><meta data-react-helmet="true" property="og:locale" content="en_US"/><meta data-react-helmet="true" property="og:locale:alternate" content="fr_FR"/><style data-href="/styles.496480a4cc6323386a8f.css" data-identity="gatsby-global-css">@charset "UTF-8";.szh-menu{background-color:#fff;border:1px solid rgba(0,0,0,.1);box-sizing:border-box;list-style:none;margin:0;padding:0;width:-webkit-max-content;width:max-content;z-index:100}.szh-menu:focus{outline:none}.szh-menu__arrow{background-color:#fff;border-color:rgba(0,0,0,.1) transparent transparent rgba(0,0,0,.1);border-style:solid;border-width:1px;box-sizing:border-box;height:.75rem;width:.75rem;z-index:-1}.szh-menu__arrow--dir-left{right:-.375rem;transform:translateY(-50%) rotate(135deg)}.szh-menu__arrow--dir-right{left:-.375rem;transform:translateY(-50%) rotate(-45deg)}.szh-menu__arrow--dir-top{bottom:-.375rem;transform:translateX(-50%) rotate(-135deg)}.szh-menu__arrow--dir-bottom{top:-.375rem;transform:translateX(-50%) rotate(45deg)}.szh-menu__item{cursor:pointer}.szh-menu__item:focus{outline:none}.szh-menu__item--hover{background-color:#ebebeb}.szh-menu__item--focusable{background-color:inherit;cursor:default}.szh-menu__item--disabled{color:#aaa;cursor:default}.szh-menu__group{box-sizing:border-box}.szh-menu__radio-group{list-style:none;margin:0;padding:0}.szh-menu__divider{background-color:rgba(0,0,0,.12);height:1px;margin:.5rem 0}.szh-menu-button{box-sizing:border-box}.szh-menu{border:none;border-radius:.25rem;box-shadow:0 3px 7px rgba(0,0,0,.133),0 .6px 2px rgba(0,0,0,.1);color:#212529;min-width:10rem;padding:.5rem 0;-webkit-user-select:none;user-select:none}.szh-menu__item{align-items:center;display:flex;padding:.375rem 1.5rem;position:relative}.szh-menu-container--itemTransition .szh-menu__item{transition-duration:.15s;transition-property:background-color,color;transition-timing-function:ease-in-out}.szh-menu__item--type-radio{padding-left:2.2rem}.szh-menu__item--type-radio:before{content:"○";font-size:.8rem;left:.8rem;position:absolute;top:.55rem}.szh-menu__item--type-radio.szh-menu__item--checked:before{content:"●"}.szh-menu__item--type-checkbox{padding-left:2.2rem}.szh-menu__item--type-checkbox:before{left:.8rem;position:absolute}.szh-menu__item--type-checkbox.szh-menu__item--checked:before{content:"✔"}.szh-menu__submenu>.szh-menu__item{padding-right:2.5rem}.szh-menu__submenu>.szh-menu__item:after{content:"❯";position:absolute;right:1rem}.szh-menu__header{color:#888;font-size:.8rem;padding:.2rem 1.5rem;text-transform:uppercase}@keyframes szh-menu-show-slide-left{0%{opacity:0;transform:translateX(.75rem)}}@keyframes szh-menu-hide-slide-left{to{opacity:0;transform:translateX(.75rem)}}@keyframes szh-menu-show-slide-right{0%{opacity:0;transform:translateX(-.75rem)}}@keyframes szh-menu-hide-slide-right{to{opacity:0;transform:translateX(-.75rem)}}@keyframes szh-menu-show-slide-top{0%{opacity:0;transform:translateY(.75rem)}}@keyframes szh-menu-hide-slide-top{to{opacity:0;transform:translateY(.75rem)}}@keyframes szh-menu-show-slide-bottom{0%{opacity:0;transform:translateY(-.75rem)}}@keyframes szh-menu-hide-slide-bottom{to{opacity:0;transform:translateY(-.75rem)}}.szh-menu--state-opening.szh-menu--dir-left{animation:szh-menu-show-slide-left .15s ease-out}.szh-menu--state-closing.szh-menu--dir-left{animation:szh-menu-hide-slide-left .15s ease-in forwards}.szh-menu--state-opening.szh-menu--dir-right{animation:szh-menu-show-slide-right .15s ease-out}.szh-menu--state-closing.szh-menu--dir-right{animation:szh-menu-hide-slide-right .15s ease-in forwards}.szh-menu--state-opening.szh-menu--dir-top{animation:szh-menu-show-slide-top .15s ease-out}.szh-menu--state-closing.szh-menu--dir-top{animation:szh-menu-hide-slide-top .15s ease-in forwards}.szh-menu--state-opening.szh-menu--dir-bottom{animation:szh-menu-show-slide-bottom .15s ease-out}.szh-menu--state-closing.szh-menu--dir-bottom{animation:szh-menu-hide-slide-bottom .15s ease-in forwards}.slick-slider{-webkit-touch-callout:none;-webkit-tap-highlight-color:transparent;box-sizing:border-box;touch-action:pan-y;-webkit-user-select:none;user-select:none;-khtml-user-select:none}.slick-list,.slick-slider{display:block;position:relative}.slick-list{margin:0;overflow:hidden;padding:0}.slick-list:focus{outline:none}.slick-list.dragging{cursor:pointer;cursor:hand}.slick-slider .slick-list,.slick-slider .slick-track{transform:translateZ(0)}.slick-track{display:block;left:0;margin-left:auto;margin-right:auto;position:relative;top:0}.slick-track:after,.slick-track:before{content:"";display:table}.slick-track:after{clear:both}.slick-loading .slick-track{visibility:hidden}.slick-slide{display:none;float:left;height:100%;min-height:1px}[dir=rtl] .slick-slide{float:right}.slick-slide img{display:block}.slick-slide.slick-loading img{display:none}.slick-slide.dragging img{pointer-events:none}.slick-initialized .slick-slide{display:block}.slick-loading .slick-slide{visibility:hidden}.slick-vertical .slick-slide{border:1px solid transparent;display:block;height:auto}.slick-arrow.slick-hidden{display:none}.slick-loading .slick-list{background:#fff url(data:image/gif;base64,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) 50% no-repeat}@font-face{font-family:slick;font-style:normal;font-weight:400;src:url(data:application/vnd.ms-fontobject;base64,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);src:url(data:application/vnd.ms-fontobject;base64,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?#iefix) format("embedded-opentype"),url(data:font/woff;base64,d09GRk9UVE8AAAVkAAsAAAAAB1wAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAABDRkYgAAABCAAAAi4AAAKbH/pWDkZGVE0AAAM4AAAAGgAAABxt0civR0RFRgAAA1QAAAAcAAAAIAAyAARPUy8yAAADcAAAAFIAAABgUBj/rmNtYXAAAAPEAAAAUAAAAWIiC0SwaGVhZAAABBQAAAAuAAAANgABMftoaGVhAAAERAAAABwAAAAkA+UCA2htdHgAAARgAAAADgAAAA4ESgBKbWF4cAAABHAAAAAGAAAABgAFUABuYW1lAAAEeAAAANwAAAFuBSeBwnBvc3QAAAVUAAAAEAAAACAAAwABeJw9ks9vEkEUx2cpWyeUoFYgNkHi2Wt7N3rVm3cTs3UVLC4LxIWEQvi1P3i7O1tYLJDAmlgKGEhQrsajf0j7J3jYTXrQWUrMJG+++b55n5e8NwwKBhHDMLv5kxT3ATEBxKBn3qOAl9zxHgb1MAPhHQgHkyF08Gr/L8B/Eb6zWnmCJ7AJVLubQOheArXvJ1A4EXi6j4I+Zg9F0QFKvsnlBCmXeve+sFEnb/nCptdtQ4QYhVFRAT1HrF8UQK/RL/SbmUbclsvGVFXRZKDHUE38cc4qpkbAAsuwiImvro+ufcfaOIQ6szlrmjRJDaKZKnbjN3GWKIbiIzRFUfCffuxxKOL+3LDlDVvx2TdxN84qZEsnhNBa6pgm2dAsnzbLsETdsmRFxUeHV4e+I2/ptN8TyqV8T3Dt29t7EYOuajVIw2y1Wy3M86w0zg/Fz2IvawmQAUHOVrPVfLkoScVynsqsTG0MGUs4z55nh3mnOJa+li+rl9WpPIcFfDubDeaDC+fLBdYN3QADzLauGfj4B6sZmq6CCpqmtSvF0qlUl2qf5AJIUCSlTqlb7lUG+LRfGzZGzZEyBgccMu6MuqPecNDvD4Y9Kjtj4gD+DsvKVMTcMdtqtZtmkzQstQvYje7Syep0PDSAhSOeHYXYWThEF//A/0YvYV1fSQtpKU5STtrhbQ444OtpKSWJIg3pOg8cBs7maTY1EZf07aq+hjWs7IWzdCYTGhb2CtZ47x+Uhx28AAB4nGNgYGBkAIJz765vANHnCyvqYTQAWnkHswAAeJxjYGRgYOADYgkGEGBiYARCFjAG8RgABHYAN3icY2BmYmCcwMDKwMHow5jGwMDgDqW/MkgytDAwMDGwcjKAQQMDAyOQUmCAgoA01xQGB4ZExUmMD/4/YNBjvP3/NgNEDQPjbbBKBQZGADfLDgsAAHicY2BgYGaAYBkGRgYQiAHyGMF8FgYHIM3DwMHABGQzMCQqKClOUJz0/z9YHRLv/+L7D+8V3cuHmgAHjGwM6ELUByxUMIOZCmbgAAA5LQ8XeJxjYGRgYABiO68w73h+m68M3EwMIHC+sKIeTqsyqDLeZrwN5HIwgKUB/aYJUgAAeJxjYGRgYLzNwMCgx8QAAkA2IwMqYAIAMGIB7QIAAAACAAAlACUAJQAlAAAAAFAAAAUAAHicbY49asNAEIU/2ZJDfkiRIvXapUFCEqpcptABUrg3ZhEiQoKVfY9UqVLlGDlADpAT5e16IUWysMz3hjfzBrjjjQT/EjKpCy+4YhN5yZoxcirPe+SMWz4jr6S+5UzSa3VuwpTnBfc8RF7yxDZyKs9r5IxHPiKv1P9iZqDnyAvMQ39UecbScVb/gJO03Xk4CFom3XYK1clhMdQUlKo7/d9NF13RkIdfy+MV7TSe2sl11tRFaXYmJKpWTd7kdVnJ8veevZKc+n3I93t9Jnvr5n4aTVWU/0z9AI2qMkV4nGNgZkAGjAxoAAAAjgAF) format("woff"),url(data:font/ttf;base64,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) format("truetype"),url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciLz4=#slick) format("svg")}.slick-next,.slick-prev{border:none;cursor:pointer;display:block;font-size:0;height:20px;line-height:0;padding:0;position:absolute;top:50%;transform:translateY(-50%);width:20px}.slick-next,.slick-next:focus,.slick-next:hover,.slick-prev,.slick-prev:focus,.slick-prev:hover{background:transparent;color:transparent;outline:none}.slick-next:focus:before,.slick-next:hover:before,.slick-prev:focus:before,.slick-prev:hover:before{opacity:1}.slick-next.slick-disabled:before,.slick-prev.slick-disabled:before{opacity:.25}.slick-next:before,.slick-prev:before{-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;color:#fff;font-family:slick;font-size:20px;line-height:1;opacity:.75}.slick-prev{left:-25px}[dir=rtl] .slick-prev{left:auto;right:-25px}.slick-prev:before{content:"←"}[dir=rtl] .slick-prev:before{content:"→"}.slick-next{right:-25px}[dir=rtl] .slick-next{left:-25px;right:auto}.slick-next:before{content:"→"}[dir=rtl] .slick-next:before{content:"←"}.slick-dotted.slick-slider{margin-bottom:30px}.slick-dots{bottom:-25px;display:block;list-style:none;margin:0;padding:0;position:absolute;text-align:center;width:100%}.slick-dots li{display:inline-block;margin:0 5px;padding:0;position:relative}.slick-dots li,.slick-dots li button{cursor:pointer;height:20px;width:20px}.slick-dots li button{background:transparent;border:0;color:transparent;display:block;font-size:0;line-height:0;outline:none;padding:5px}.slick-dots li button:focus,.slick-dots li button:hover{outline:none}.slick-dots li button:focus:before,.slick-dots li button:hover:before{opacity:1}.slick-dots li button:before{-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;color:#000;content:"•";font-family:slick;font-size:6px;height:20px;left:0;line-height:20px;opacity:.25;position:absolute;text-align:center;top:0;width:20px}.slick-dots li.slick-active button:before{color:#000;opacity:.75}</style><link rel="icon" href="/favicon-32x32.png?v=30523dcaa90959843f32c17170c559d3" type="image/png"/><link rel="manifest" href="/manifest.webmanifest" crossorigin="anonymous"/><link rel="apple-touch-icon" sizes="48x48" href="/icons/icon-48x48.png?v=30523dcaa90959843f32c17170c559d3"/><link rel="apple-touch-icon" sizes="72x72" href="/icons/icon-72x72.png?v=30523dcaa90959843f32c17170c559d3"/><link rel="apple-touch-icon" sizes="96x96" href="/icons/icon-96x96.png?v=30523dcaa90959843f32c17170c559d3"/><link rel="apple-touch-icon" sizes="144x144" href="/icons/icon-144x144.png?v=30523dcaa90959843f32c17170c559d3"/><link rel="apple-touch-icon" sizes="192x192" href="/icons/icon-192x192.png?v=30523dcaa90959843f32c17170c559d3"/><link rel="apple-touch-icon" sizes="256x256" href="/icons/icon-256x256.png?v=30523dcaa90959843f32c17170c559d3"/><link rel="apple-touch-icon" sizes="384x384" href="/icons/icon-384x384.png?v=30523dcaa90959843f32c17170c559d3"/><link rel="apple-touch-icon" sizes="512x512" href="/icons/icon-512x512.png?v=30523dcaa90959843f32c17170c559d3"/><style>.gatsby-image-wrapper{position:relative;overflow:hidden}.gatsby-image-wrapper picture.object-fit-polyfill{position:static!important}.gatsby-image-wrapper img{bottom:0;height:100%;left:0;margin:0;max-width:none;padding:0;position:absolute;right:0;top:0;width:100%;object-fit:cover}.gatsby-image-wrapper [data-main-image]{opacity:0;transform:translateZ(0);transition:opacity .25s linear;will-change:opacity}.gatsby-image-wrapper-constrained{display:inline-block;vertical-align:top}</style><noscript><style>.gatsby-image-wrapper noscript [data-main-image]{opacity:1!important}.gatsby-image-wrapper [data-placeholder-image]{opacity:0!important}</style></noscript><script type="module">const e="undefined"!=typeof HTMLImageElement&&"loading"in HTMLImageElement.prototype;e&&document.body.addEventListener("load",(function(e){const t=e.target;if(void 0===t.dataset.mainImage)return;if(void 0===t.dataset.gatsbyImageSsr)return;let a=null,n=t;for(;null===a&&n;)void 0!==n.parentNode.dataset.gatsbyImageWrapper&&(a=n.parentNode),n=n.parentNode;const o=a.querySelector("[data-placeholder-image]"),r=new Image;r.src=t.currentSrc,r.decode().catch((()=>{})).then((()=>{t.style.opacity=1,o&&(o.style.opacity=0,o.style.transition="opacity 500ms linear")}))}),!0);</script><link data-react-helmet="true" rel="alternate" hrefLang="x-default" href="https://www.umr-lastig.fr"/><link data-react-helmet="true" rel="alternate" hrefLang="en-US" href="https://www.umr-lastig.fr/members/Loic-Landrieu/"/><link data-react-helmet="true" rel="alternate" hrefLang="fr-FR" href="https://www.umr-lastig.fr/fr/members/Loic-Landrieu/"/><link rel="stylesheet" href="https://unpkg.com/leaflet@1.9.3/dist/leaflet.css" integrity="sha256-kLaT2GOSpHechhsozzB+flnD+zUyjE2LlfWPgU04xyI=" crossorigin=""/><style data-styled="" data-styled-version="6.1.12">html,body,#___gatsby{height:100%;}/*!sc*/
body{margin:0px;font-family:sans-serif;}/*!sc*/
#gatsby-focus-wrapper{height:100%;}/*!sc*/
div[role="group"][tabindex]{height:100%;}/*!sc*/
a{text-decoration:none;color:#0978da;}/*!sc*/
data-styled.g1[id="sc-global-eJVbrA1"]{content:"sc-global-eJVbrA1,"}/*!sc*/
.epUEzV{display:flex;flex-direction:column;minheight:100vh;height:100%;justify-content:space-between;}/*!sc*/
data-styled.g3[id="Containerstyled__VerticalContainer-sc-1u2w6cg-0"]{content:"epUEzV,"}/*!sc*/
.kCoNxb{width:100%;display:flex;flex-direction:column;align-items:center;}/*!sc*/
data-styled.g4[id="Containerstyled__MainContainer-sc-1u2w6cg-1"]{content:"kCoNxb,"}/*!sc*/
.bPuwMk{display:flex;flex-direction:row;justify-content:space-between;margin:0 50px;}/*!sc*/
data-styled.g5[id="Containerstyled__HorizontalContainer-sc-1u2w6cg-2"]{content:"bPuwMk,"}/*!sc*/
.ohOHN{display:flex;flex-direction:row;place-items:center;justify-content:center;margin:0 50px;}/*!sc*/
data-styled.g6[id="Containerstyled__HorizontalCenteredContainer-sc-1u2w6cg-3"]{content:"ohOHN,"}/*!sc*/
.gqtEdE{width:100%;background-color:#f4f4f4;}/*!sc*/
data-styled.g8[id="Footerstyled__Footer-sc-r3nxg5-0"]{content:"gqtEdE,"}/*!sc*/
.kcvdpX{width:100%;text-align:left;padding:2px;background-color:#f4f4f4;color:#000000;}/*!sc*/
.kcvdpX:hover{background-color:#2269a6;}/*!sc*/
.kcvdpX a{width:100%;text-align:left;padding:0;margin-left:0;background-color:#f4f4f4;color:#000000;text-decoration:none;}/*!sc*/
.kcvdpX a:hover{background-color:#2269a6;}/*!sc*/
.kcvdpX img{width:auto;height:60px;}/*!sc*/
data-styled.g10[id="Dropdownstyled__Button-sc-5ucibi-1"]{content:"kcvdpX,"}/*!sc*/
.kaUEIN{background:#f4f4f4;height:80px;display:flex;justify-content:center;font-size:1rem;position:sticky;top:0;z-index:1000;}/*!sc*/
@media screen and (max-width:960px){.kaUEIN{transition:0.8s all ease;}}/*!sc*/
data-styled.g12[id="NavBarstyled__Nav-sc-hjr4g0-0"]{content:"kaUEIN,"}/*!sc*/
.juiozz{display:flex;justify-content:space-between;height:80px;z-index:1;width:100%;max-width:1000px;margin:0 auto;}/*!sc*/
data-styled.g13[id="NavBarstyled__NavBarContainer-sc-hjr4g0-1"]{content:"juiozz,"}/*!sc*/
.hRixcn{color:#fff;color:#f4f4f4;justify-self:flex-start;cursor:pointer;text-decoration:none;font-size:1.8rem;display:flex;align-items:center;font-weight:600;margin-left:2rem;}/*!sc*/
data-styled.g14[id="NavBarstyled__NavBarLogo-sc-hjr4g0-2"]{content:"hRixcn,"}/*!sc*/
.caAhIS{display:none;}/*!sc*/
@media screen and (max-width:960px){.caAhIS{display:block;position:absolute;top:0;right:0;transform:translate(-100%,60%);font-size:2rem;cursor:pointer;}}/*!sc*/
data-styled.g16[id="NavBarstyled__MobileIcon-sc-hjr4g0-4"]{content:"caAhIS,"}/*!sc*/
.dCSciJ{display:flex;align-items:center;list-style:none;text-align:center;}/*!sc*/
@media screen and (max-width:960px){.dCSciJ{display:none;flex-direction:column;width:100%;position:absolute;margin:0;top:80px;opacity:1;padding:0;background:#f4f4f4;}}/*!sc*/
data-styled.g17[id="NavBarstyled__NavBarMenu-sc-hjr4g0-5"]{content:"dCSciJ,"}/*!sc*/
.bxlPwW{height:80px;}/*!sc*/
@media screen and (max-width:960px){.bxlPwW{width:100%;background:inherit;padding:0;}.bxlPwW a{padding:0;}}/*!sc*/
data-styled.g18[id="NavBarstyled__NavItem-sc-hjr4g0-6"]{content:"bxlPwW,"}/*!sc*/
.chYixJ{color:#000;display:flex;align-items:center;text-decoration:none;padding:0rem 1rem;height:100%;}/*!sc*/
@media screen and (max-width:960px){.chYixJ{height:80px;text-align:center;padding:0rem 1rem;width:100%;display:table;}.chYixJ:hover{color:#ff4040;transition:all 0.3s ease;}}/*!sc*/
data-styled.g19[id="NavBarstyled__NavLink-sc-hjr4g0-7"]{content:"chYixJ,"}/*!sc*/
.hEeQqk{color:#000;display:flex;align-items:center;text-decoration:none;padding:0rem 1rem;height:100%;}/*!sc*/
@media screen and (max-width:960px){.hEeQqk{height:80px;text-align:center;padding:0rem 1rem;width:100%;display:table;}.hEeQqk:hover{color:#ff4040;}}/*!sc*/
data-styled.g20[id="NavBarstyled__NavLinkNoLocale-sc-hjr4g0-8"]{content:"hEeQqk,"}/*!sc*/
.dBRgsz{color:#000;display:flex;align-items:center;text-decoration:none;padding:0rem 1rem;height:100%;border:none;background:inherit;font-size:1rem;cursor:pointer;}/*!sc*/
@media screen and (max-width:960px){.dBRgsz{text-align:center;padding:2rem;height:80px;width:100%;display:table;}.dBRgsz:hover{color:#ff4040;transition:all 0.3s ease;}}/*!sc*/
data-styled.g21[id="NavBarstyled__NavMenuButton-sc-hjr4g0-9"]{content:"dBRgsz,"}/*!sc*/
.gcWXFJ{background:#f4f4f4;}/*!sc*/
.gcWXFJ ul{background:inherit;}/*!sc*/
data-styled.g22[id="NavBarstyled__NavMenu-sc-hjr4g0-10"]{content:"gcWXFJ,"}/*!sc*/
.bJhdgp{width:100%;}/*!sc*/
data-styled.g26[id="Publicationsstyled__StyledPublicationList-sc-997srn-1"]{content:"bJhdgp,"}/*!sc*/
.IxZzp{margin:1rem;width:100%;}/*!sc*/
.IxZzp span a{color:#6c757d;text-decoration:none;}/*!sc*/
.IxZzp span a:not(:last-child)::after{content:", ";}/*!sc*/
.IxZzp span a:last-child::after{content:". ";}/*!sc*/
.IxZzp a{color:#0978da;text-decoration:none;}/*!sc*/
data-styled.g27[id="Publicationsstyled__Publication-sc-997srn-2"]{content:"IxZzp,"}/*!sc*/
.ccodOT{width:32px;height:32px;display:block;float:right;}/*!sc*/
.ccodOT svg{width:100%;height:100%;}/*!sc*/
.ccodOT button{width:100%;height:100%;background-color:transparent;border:none;}/*!sc*/
.ccodOT iconify-icon svg{width:2em;height:2em;}/*!sc*/
.ccodOT a{color:#0978da;text-decoration:none;}/*!sc*/
data-styled.g28[id="Publicationsstyled__ImageLink-sc-997srn-3"]{content:"ccodOT,"}/*!sc*/
.fOoitX{display:flex;flex-direction:column;align-items:center;margin:auto;}/*!sc*/
.fOoitX img{width:200px;}/*!sc*/
.fOoitX a{padding:10px;}/*!sc*/
data-styled.g29[id="MemberPagestyled__StyledMemberPage-sc-t534vo-0"]{content:"fOoitX,"}/*!sc*/
.hmkOFC{display:flex;flex-direction:row;align-items:center;}/*!sc*/
data-styled.g30[id="MemberPagestyled__Ids-sc-t534vo-1"]{content:"hmkOFC,"}/*!sc*/
.hYjRZs{display:flex;flex-direction:column;align-items:center;max-height:400px;}/*!sc*/
data-styled.g31[id="MemberPagestyled__StyledWordCloud-sc-t534vo-2"]{content:"hYjRZs,"}/*!sc*/
</style></head><body><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><div class="Containerstyled__VerticalContainer-sc-1u2w6cg-0 epUEzV"><nav class="NavBarstyled__Nav-sc-hjr4g0-0 kaUEIN"><div class="NavBarstyled__NavBarContainer-sc-hjr4g0-1 juiozz"><a class="NavBarstyled__NavBarLogo-sc-hjr4g0-2 hRixcn" href="/"><div data-gatsby-image-wrapper="" class="gatsby-image-wrapper gatsby-image-wrapper-constrained"><div style="max-width:149px;display:block"><img alt="" role="presentation" aria-hidden="true" src="data:image/svg+xml;charset=utf-8,%3Csvg%20height=&#x27;60&#x27;%20width=&#x27;149&#x27;%20xmlns=&#x27;http://www.w3.org/2000/svg&#x27;%20version=&#x27;1.1&#x27;%3E%3C/svg%3E" style="max-width:100%;display:block;position:static"/></div><div aria-hidden="true" data-placeholder-image="" style="opacity:1;transition:opacity 500ms linear;background-color:#080808;position:absolute;top:0;left:0;bottom:0;right:0"></div><picture><source type="image/webp" data-srcset="/static/3934632620aaa2af9ec6f08a9874424d/dbb2c/lastig1.webp 37w,/static/3934632620aaa2af9ec6f08a9874424d/61789/lastig1.webp 75w,/static/3934632620aaa2af9ec6f08a9874424d/7179c/lastig1.webp 149w,/static/3934632620aaa2af9ec6f08a9874424d/96003/lastig1.webp 298w" sizes="(min-width: 149px) 149px, 100vw"/><img data-gatsby-image-ssr="" data-main-image="" style="opacity:0" sizes="(min-width: 149px) 149px, 100vw" decoding="async" loading="lazy" data-src="/static/3934632620aaa2af9ec6f08a9874424d/5f98c/lastig1.svg" data-srcset="/static/3934632620aaa2af9ec6f08a9874424d/7f138/lastig1.svg 37w,/static/3934632620aaa2af9ec6f08a9874424d/6ffb4/lastig1.svg 75w,/static/3934632620aaa2af9ec6f08a9874424d/5f98c/lastig1.svg 149w,/static/3934632620aaa2af9ec6f08a9874424d/177b1/lastig1.svg 298w" alt="LASTIG LOGO"/></picture><noscript><picture><source type="image/webp" srcSet="/static/3934632620aaa2af9ec6f08a9874424d/dbb2c/lastig1.webp 37w,/static/3934632620aaa2af9ec6f08a9874424d/61789/lastig1.webp 75w,/static/3934632620aaa2af9ec6f08a9874424d/7179c/lastig1.webp 149w,/static/3934632620aaa2af9ec6f08a9874424d/96003/lastig1.webp 298w" sizes="(min-width: 149px) 149px, 100vw"/><img data-gatsby-image-ssr="" data-main-image="" style="opacity:0" sizes="(min-width: 149px) 149px, 100vw" decoding="async" loading="lazy" src="/static/3934632620aaa2af9ec6f08a9874424d/5f98c/lastig1.svg" srcSet="/static/3934632620aaa2af9ec6f08a9874424d/7f138/lastig1.svg 37w,/static/3934632620aaa2af9ec6f08a9874424d/6ffb4/lastig1.svg 75w,/static/3934632620aaa2af9ec6f08a9874424d/5f98c/lastig1.svg 149w,/static/3934632620aaa2af9ec6f08a9874424d/177b1/lastig1.svg 298w" alt="LASTIG LOGO"/></picture></noscript><script type="module">const t="undefined"!=typeof HTMLImageElement&&"loading"in HTMLImageElement.prototype;if(t){const t=document.querySelectorAll("img[data-main-image]");for(let e of t){e.dataset.src&&(e.setAttribute("src",e.dataset.src),e.removeAttribute("data-src")),e.dataset.srcset&&(e.setAttribute("srcset",e.dataset.srcset),e.removeAttribute("data-srcset"));const t=e.parentNode.querySelectorAll("source[data-srcset]");for(let e of t)e.setAttribute("srcset",e.dataset.srcset),e.removeAttribute("data-srcset");e.complete&&(e.style.opacity=1,e.parentNode.parentNode.querySelector("[data-placeholder-image]").style.opacity=0)}}</script></div></a><div class="NavBarstyled__MobileIcon-sc-hjr4g0-4 caAhIS"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" style="color:#131313" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 132h416c8.837 0 16-7.163 16-16V76c0-8.837-7.163-16-16-16H16C7.163 60 0 67.163 0 76v40c0 8.837 7.163 16 16 16zm0 160h416c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h416c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16z"></path></svg></div><ul class="NavBarstyled__NavBarMenu-sc-hjr4g0-5 dCSciJ"><li class="NavBarstyled__NavItem-sc-hjr4g0-6 bxlPwW"><button aria-haspopup="true" aria-expanded="false" type="button" class="szh-menu-button NavBarstyled__NavMenuButton-sc-hjr4g0-9 dBRgsz">Lab</button></li><li class="NavBarstyled__NavItem-sc-hjr4g0-6 bxlPwW"><button aria-haspopup="true" aria-expanded="false" type="button" class="szh-menu-button NavBarstyled__NavMenuButton-sc-hjr4g0-9 dBRgsz">Research</button></li><li class="NavBarstyled__NavItem-sc-hjr4g0-6 bxlPwW"><button aria-haspopup="true" aria-expanded="false" type="button" class="szh-menu-button NavBarstyled__NavMenuButton-sc-hjr4g0-9 dBRgsz">Production</button></li><li class="NavBarstyled__NavItem-sc-hjr4g0-6 bxlPwW"><a href="https://www.umr-lastig.fr/seminars/" class="NavBarstyled__NavLinkNoLocale-sc-hjr4g0-8 hEeQqk">Seminars</a></li><li class="NavBarstyled__NavItem-sc-hjr4g0-6 bxlPwW"><a class="NavBarstyled__NavLink-sc-hjr4g0-7 chYixJ" href="/join/">Join us</a></li></ul><button aria-haspopup="true" aria-expanded="false" type="button" class="szh-menu-button NavBarstyled__NavMenuButton-sc-hjr4g0-9 dBRgsz"><img src="https://languageicon.org/language-icon.svg" alt="Language" style="width:32px;height:32px"/></button></div></nav><main><div class="Containerstyled__MainContainer-sc-1u2w6cg-1 kCoNxb"><div class="MemberPagestyled__StyledMemberPage-sc-t534vo-0 fOoitX"><h1>Loic<!-- --> <!-- -->Landrieu</h1><div><div data-gatsby-image-wrapper="" class="gatsby-image-wrapper gatsby-image-wrapper-constrained"><div style="max-width:200px;display:block"><img alt="" role="presentation" aria-hidden="true" src="data:image/svg+xml;charset=utf-8,%3Csvg%20height=&#x27;200&#x27;%20width=&#x27;200&#x27;%20xmlns=&#x27;http://www.w3.org/2000/svg&#x27;%20version=&#x27;1.1&#x27;%3E%3C/svg%3E" style="max-width:100%;display:block;position:static"/></div><div aria-hidden="true" data-placeholder-image="" style="opacity:1;transition:opacity 500ms linear;background-color:#f8f8f8;position:absolute;top:0;left:0;bottom:0;right:0"></div><picture><source type="image/webp" data-srcset="/static/b597e44f3b93949a0994651acfa06b73/dbc4a/landrieu.webp 50w,/static/b597e44f3b93949a0994651acfa06b73/d8057/landrieu.webp 100w,/static/b597e44f3b93949a0994651acfa06b73/2e34e/landrieu.webp 200w,/static/b597e44f3b93949a0994651acfa06b73/416c3/landrieu.webp 400w" sizes="(min-width: 200px) 200px, 100vw"/><img data-gatsby-image-ssr="" aspectratio="1" data-main-image="" style="opacity:0" sizes="(min-width: 200px) 200px, 100vw" decoding="async" loading="lazy" data-src="/static/b597e44f3b93949a0994651acfa06b73/dd515/landrieu.jpg" data-srcset="/static/b597e44f3b93949a0994651acfa06b73/6ac16/landrieu.jpg 50w,/static/b597e44f3b93949a0994651acfa06b73/e07e1/landrieu.jpg 100w,/static/b597e44f3b93949a0994651acfa06b73/dd515/landrieu.jpg 200w,/static/b597e44f3b93949a0994651acfa06b73/47930/landrieu.jpg 400w" alt="Loic Landrieu"/></picture><noscript><picture><source type="image/webp" srcSet="/static/b597e44f3b93949a0994651acfa06b73/dbc4a/landrieu.webp 50w,/static/b597e44f3b93949a0994651acfa06b73/d8057/landrieu.webp 100w,/static/b597e44f3b93949a0994651acfa06b73/2e34e/landrieu.webp 200w,/static/b597e44f3b93949a0994651acfa06b73/416c3/landrieu.webp 400w" sizes="(min-width: 200px) 200px, 100vw"/><img data-gatsby-image-ssr="" aspectratio="1" data-main-image="" style="opacity:0" sizes="(min-width: 200px) 200px, 100vw" decoding="async" loading="lazy" src="/static/b597e44f3b93949a0994651acfa06b73/dd515/landrieu.jpg" srcSet="/static/b597e44f3b93949a0994651acfa06b73/6ac16/landrieu.jpg 50w,/static/b597e44f3b93949a0994651acfa06b73/e07e1/landrieu.jpg 100w,/static/b597e44f3b93949a0994651acfa06b73/dd515/landrieu.jpg 200w,/static/b597e44f3b93949a0994651acfa06b73/47930/landrieu.jpg 400w" alt="Loic Landrieu"/></picture></noscript><script type="module">const t="undefined"!=typeof HTMLImageElement&&"loading"in HTMLImageElement.prototype;if(t){const t=document.querySelectorAll("img[data-main-image]");for(let e of t){e.dataset.src&&(e.setAttribute("src",e.dataset.src),e.removeAttribute("data-src")),e.dataset.srcset&&(e.setAttribute("srcset",e.dataset.srcset),e.removeAttribute("data-srcset"));const t=e.parentNode.querySelectorAll("source[data-srcset]");for(let e of t)e.setAttribute("srcset",e.dataset.srcset),e.removeAttribute("data-srcset");e.complete&&(e.style.opacity=1,e.parentNode.parentNode.querySelector("[data-placeholder-image]").style.opacity=0)}}</script></div></div><h2>Associate researcher</h2><h3>STRUDEL team(s)</h3><a href="https://loiclandrieu.com/">Personal webpage</a><div class="MemberPagestyled__Ids-sc-t534vo-1 hmkOFC"><a href="https://cv.hal.science/loic-landrieu" aria-label="HAL"><iconify-icon icon="simple-icons:hal" width="2em" height="2em"></iconify-icon></a><a href="https://orcid.org/0000-0002-7738-8141" aria-label="orcid"><iconify-icon icon="simple-icons:orcid" width="2em" height="2em"></iconify-icon></a><a href="https://www.idref.fr/225451042" aria-label="idref"><iconify-icon icon="token:id" width="2em" height="2em"></iconify-icon></a></div><svg viewBox="0 0 1200 400" data-testid="RWC__WordCloud-svg"><g transform="translate(600,200)"></g></svg><div style="opacity:0;transition:all 300ms ease;pointer-events:none;background:rgba(0, 0, 0, 0.75);color:#fff;padding:8px 12px;border-radius:4px;transform:translate(10px, 10px);white-space:nowrap;display:flex;align-items:center;gap:10px;position:absolute;left:0;top:0" data-testid="RWC__DefaultTooltipRenderer-container"><span style="font-weight:bold;font-size:14px;font-family:Arial" data-testid="RWC__DefaultTooltipRenderer-text"></span><span style="font-size:12px;font-family:monospace" data-testid="RWC__DefaultTooltipRenderer-value"></span></div><h1>Publications</h1><div><div id="pubACL"><h2> <!-- -->International Journals<!-- --> </h2><table class="Publicationsstyled__StyledPublicationList-sc-997srn-1 bJhdgp"><thead></thead><tbody><tr class="Publicationsstyled__Publication-sc-997srn-2 IxZzp"><td><div aria-label="Team" style="width:32px;height:32px;background:conic-gradient(#984ea3 0deg 360deg);border-radius:5px"></div></td><td><span><a>Ekaterina Kalinicheva</a><a href="https://cv.archives-ouvertes.fr/loic-landrieu">Loic Landrieu</a><a href="https://cv.archives-ouvertes.fr/clement-mallet">Clément Mallet</a><a>Nesrine Chehata</a></span><a href="https://hal.science/hal-03727656">Predicting Vegetation Stratum Occupancy from Airborne LiDAR Data with Deep Learning. </a><span><i>International Journal of Applied Earth Observation and Geoinformation</i>, 2022, 112, pp.102863. <a target="_blank" href="https://dx.doi.org/10.1016/j.jag.2022.102863">&#x27E8;10.1016/j.jag.2022.102863&#x27E9;</a></span></td><td></td><td></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://www.doi.org/10.1016/j.jag.2022.102863" aria-label="Document page using DOI"><iconify-icon icon="academicons:doi" width="2em" height="2em"></iconify-icon></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://hal.science/hal-03727656/document" aria-label="Main document in HAL"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 64C0 28.7 28.7 0 64 0L224 0l0 128c0 17.7 14.3 32 32 32l128 0 0 144-208 0c-35.3 0-64 28.7-64 64l0 144-48 0c-35.3 0-64-28.7-64-64L0 64zm384 64l-128 0L256 0 384 128zM176 352l32 0c30.9 0 56 25.1 56 56s-25.1 56-56 56l-16 0 0 32c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-48 0-80c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24l-16 0 0 48 16 0zm96-80l32 0c26.5 0 48 21.5 48 48l0 64c0 26.5-21.5 48-48 48l-32 0c-8.8 0-16-7.2-16-16l0-128c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16l0-64c0-8.8-7.2-16-16-16l-16 0 0 96 16 0zm80-112c0-8.8 7.2-16 16-16l48 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 32 32 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 48c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-64 0-64z"></path></svg></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"> <button aria-label="Copy the bibtex to the clipboard"> <iconify-icon icon="file-icons:bibtex" width="2em" height="2em"></iconify-icon> </button> </div></td></tr><tr class="Publicationsstyled__Publication-sc-997srn-2 IxZzp"><td><div aria-label="Team" style="width:32px;height:32px;background:conic-gradient(#e41a1c 0deg 180deg, #984ea3 180deg 360deg);border-radius:5px"></div></td><td><span><a href="https://cv.archives-ouvertes.fr/raphael-sulzer">R. Sulzer</a><a href="https://cv.archives-ouvertes.fr/loic-landrieu">Loic Landrieu</a><a href="https://cv.archives-ouvertes.fr/renaud-marlet">Renaud Marlet</a><a href="https://cv.archives-ouvertes.fr/bruno-vallet">Bruno Vallet</a></span><a href="https://hal.science/hal-03312448">Scalable Surface Reconstruction with Delaunay-Graph Neural Networks. </a><span><i>Computer Graphics Forum</i>, 2021, Eurographics Symposium on Geometry Processing 2021, July 12 – 14, 2021, 40 (5), pp.157 - 167. <a target="_blank" href="https://dx.doi.org/10.1111/cgf.14364">&#x27E8;10.1111/cgf.14364&#x27E9;</a></span></td><td></td><td></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://www.doi.org/10.1111/cgf.14364" aria-label="Document page using DOI"><iconify-icon icon="academicons:doi" width="2em" height="2em"></iconify-icon></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://hal.science/hal-03312448/document" aria-label="Main document in HAL"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 64C0 28.7 28.7 0 64 0L224 0l0 128c0 17.7 14.3 32 32 32l128 0 0 144-208 0c-35.3 0-64 28.7-64 64l0 144-48 0c-35.3 0-64-28.7-64-64L0 64zm384 64l-128 0L256 0 384 128zM176 352l32 0c30.9 0 56 25.1 56 56s-25.1 56-56 56l-16 0 0 32c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-48 0-80c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24l-16 0 0 48 16 0zm96-80l32 0c26.5 0 48 21.5 48 48l0 64c0 26.5-21.5 48-48 48l-32 0c-8.8 0-16-7.2-16-16l0-128c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16l0-64c0-8.8-7.2-16-16-16l-16 0 0 96 16 0zm80-112c0-8.8 7.2-16 16-16l48 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 32 32 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 48c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-64 0-64z"></path></svg></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"> <button aria-label="Copy the bibtex to the clipboard"> <iconify-icon icon="file-icons:bibtex" width="2em" height="2em"></iconify-icon> </button> </div></td></tr><tr class="Publicationsstyled__Publication-sc-997srn-2 IxZzp"><td><div aria-label="Team" style="width:32px;height:32px;background:conic-gradient(#984ea3 0deg 360deg);border-radius:5px"></div></td><td><span><a>Félix Quinton</a><a href="https://cv.archives-ouvertes.fr/loic-landrieu">Loic Landrieu</a></span><a href="https://hal.science/hal-03500526">Crop Rotation Modeling for Deep Learning-Based Parcel Classification from Satellite Time Series. </a><span><i>Remote Sensing</i>, 2021, 13 (22), pp.4599. <a target="_blank" href="https://dx.doi.org/10.3390/rs13224599">&#x27E8;10.3390/rs13224599&#x27E9;</a></span></td><td></td><td></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://www.doi.org/10.3390/rs13224599" aria-label="Document page using DOI"><iconify-icon icon="academicons:doi" width="2em" height="2em"></iconify-icon></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://hal.science/hal-03500526/document" aria-label="Main document in HAL"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 64C0 28.7 28.7 0 64 0L224 0l0 128c0 17.7 14.3 32 32 32l128 0 0 144-208 0c-35.3 0-64 28.7-64 64l0 144-48 0c-35.3 0-64-28.7-64-64L0 64zm384 64l-128 0L256 0 384 128zM176 352l32 0c30.9 0 56 25.1 56 56s-25.1 56-56 56l-16 0 0 32c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-48 0-80c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24l-16 0 0 48 16 0zm96-80l32 0c26.5 0 48 21.5 48 48l0 64c0 26.5-21.5 48-48 48l-32 0c-8.8 0-16-7.2-16-16l0-128c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16l0-64c0-8.8-7.2-16-16-16l-16 0 0 96 16 0zm80-112c0-8.8 7.2-16 16-16l48 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 32 32 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 48c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-64 0-64z"></path></svg></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"> <button aria-label="Copy the bibtex to the clipboard"> <iconify-icon icon="file-icons:bibtex" width="2em" height="2em"></iconify-icon> </button> </div></td></tr><tr class="Publicationsstyled__Publication-sc-997srn-2 IxZzp"><td><div aria-label="Team" style="width:32px;height:32px;background:conic-gradient(#984ea3 0deg 360deg);border-radius:5px"></div></td><td><span><a>Sébastien Giordano</a><a>Simon Bailly</a><a href="https://cv.archives-ouvertes.fr/loic-landrieu">Loic Landrieu</a><a>Nesrine Chehata</a></span><a href="https://hal.science/hal-03500509">Improved Crop Classification with Rotation Knowledge using Sentinel-1 and -2 Time Series. </a><span><i>Photogrammetric engineering and remote sensing</i>, 2020, 86, pp.431 - 441. <a target="_blank" href="https://dx.doi.org/10.14358/pers.86.7.431">&#x27E8;10.14358/pers.86.7.431&#x27E9;</a></span></td><td></td><td></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://www.doi.org/10.14358/pers.86.7.431" aria-label="Document page using DOI"><iconify-icon icon="academicons:doi" width="2em" height="2em"></iconify-icon></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://hal.science/hal-03500509/document" aria-label="Main document in HAL"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 64C0 28.7 28.7 0 64 0L224 0l0 128c0 17.7 14.3 32 32 32l128 0 0 144-208 0c-35.3 0-64 28.7-64 64l0 144-48 0c-35.3 0-64-28.7-64-64L0 64zm384 64l-128 0L256 0 384 128zM176 352l32 0c30.9 0 56 25.1 56 56s-25.1 56-56 56l-16 0 0 32c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-48 0-80c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24l-16 0 0 48 16 0zm96-80l32 0c26.5 0 48 21.5 48 48l0 64c0 26.5-21.5 48-48 48l-32 0c-8.8 0-16-7.2-16-16l0-128c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16l0-64c0-8.8-7.2-16-16-16l-16 0 0 96 16 0zm80-112c0-8.8 7.2-16 16-16l48 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 32 32 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 48c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-64 0-64z"></path></svg></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"> <button aria-label="Copy the bibtex to the clipboard"> <iconify-icon icon="file-icons:bibtex" width="2em" height="2em"></iconify-icon> </button> </div></td></tr><tr class="Publicationsstyled__Publication-sc-997srn-2 IxZzp"><td><div aria-label="Team" style="width:32px;height:32px;background:conic-gradient(#984ea3 0deg 180deg, #e41a1c 180deg 360deg);border-radius:5px"></div></td><td><span><a href="https://cv.archives-ouvertes.fr/loic-landrieu">Loic Landrieu</a><a href="https://cv.archives-ouvertes.fr/hugo-raguet">Hugo Raguet Raguet</a><a href="https://cv.archives-ouvertes.fr/bruno-vallet">Bruno Vallet</a><a href="https://cv.archives-ouvertes.fr/clement-mallet">Clément Mallet</a><a>et al</a></span><a href="https://hal.science/hal-01505245">A structured regularization framework for spatially smoothing semantic labelings of 3D point clouds. </a><span><i>ISPRS Journal of Photogrammetry and Remote Sensing</i>, 2017, 132, pp.102-118. <a target="_blank" href="https://dx.doi.org/10.1016/j.isprsjprs.2017.08.010">&#x27E8;10.1016/j.isprsjprs.2017.08.010&#x27E9;</a></span></td><td></td><td></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://www.doi.org/10.1016/j.isprsjprs.2017.08.010" aria-label="Document page using DOI"><iconify-icon icon="academicons:doi" width="2em" height="2em"></iconify-icon></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://hal.science/hal-01505245/document" aria-label="Main document in HAL"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 64C0 28.7 28.7 0 64 0L224 0l0 128c0 17.7 14.3 32 32 32l128 0 0 144-208 0c-35.3 0-64 28.7-64 64l0 144-48 0c-35.3 0-64-28.7-64-64L0 64zm384 64l-128 0L256 0 384 128zM176 352l32 0c30.9 0 56 25.1 56 56s-25.1 56-56 56l-16 0 0 32c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-48 0-80c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24l-16 0 0 48 16 0zm96-80l32 0c26.5 0 48 21.5 48 48l0 64c0 26.5-21.5 48-48 48l-32 0c-8.8 0-16-7.2-16-16l0-128c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16l0-64c0-8.8-7.2-16-16-16l-16 0 0 96 16 0zm80-112c0-8.8 7.2-16 16-16l48 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 32 32 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 48c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-64 0-64z"></path></svg></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"> <button aria-label="Copy the bibtex to the clipboard"> <iconify-icon icon="file-icons:bibtex" width="2em" height="2em"></iconify-icon> </button> </div></td></tr><tr class="Publicationsstyled__Publication-sc-997srn-2 IxZzp"><td><div aria-label="Team" style="width:32px;height:32px;background:conic-gradient(#984ea3 0deg 360deg);border-radius:5px"></div></td><td><span><a href="https://cv.archives-ouvertes.fr/loic-landrieu">Loic Landrieu</a><a>Guillaume Obozinski</a></span><a href="https://hal.science/hal-01306779">Cut Pursuit: fast algorithms to learn piecewise constant functions on general weighted graphs. </a><span><i>SIAM Journal on Imaging Sciences</i>, 2017, Vol. 10 ( No. 4 ), pp. 1724-1766</span></td><td></td><td></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://hal.science/hal-01306779/document" aria-label="Main document in HAL"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 64C0 28.7 28.7 0 64 0L224 0l0 128c0 17.7 14.3 32 32 32l128 0 0 144-208 0c-35.3 0-64 28.7-64 64l0 144-48 0c-35.3 0-64-28.7-64-64L0 64zm384 64l-128 0L256 0 384 128zM176 352l32 0c30.9 0 56 25.1 56 56s-25.1 56-56 56l-16 0 0 32c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-48 0-80c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24l-16 0 0 48 16 0zm96-80l32 0c26.5 0 48 21.5 48 48l0 64c0 26.5-21.5 48-48 48l-32 0c-8.8 0-16-7.2-16-16l0-128c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16l0-64c0-8.8-7.2-16-16-16l-16 0 0 96 16 0zm80-112c0-8.8 7.2-16 16-16l48 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 32 32 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 48c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-64 0-64z"></path></svg></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"> <button aria-label="Copy the bibtex to the clipboard"> <iconify-icon icon="file-icons:bibtex" width="2em" height="2em"></iconify-icon> </button> </div></td></tr></tbody></table></div><div id="pubCOM"><h2> <!-- -->Communications<!-- --> </h2><table class="Publicationsstyled__StyledPublicationList-sc-997srn-1 bJhdgp"><thead></thead><tbody><tr class="Publicationsstyled__Publication-sc-997srn-2 IxZzp"><td><div aria-label="Team" style="width:32px;height:32px;background:conic-gradient(#984ea3 0deg 360deg);border-radius:5px"></div></td><td><span><a href="https://cv.archives-ouvertes.fr/gastruc">Guillaume Astruc</a><a href="https://cv.archives-ouvertes.fr/nicolas-gonthier">Nicolas Gonthier</a><a href="https://cv.archives-ouvertes.fr/clement-mallet">Clément Mallet</a><a href="https://cv.archives-ouvertes.fr/loic-landrieu">Loic Landrieu</a></span><a href="https://hal.science/hal-05016354">AnySat: a Multi-Resolution/Modality/Scale Earth Observation Model. </a><span><i>EGU24 General Assembly</i>, European Geosciences Union, Apr 2025, Vienne, Austria</span></td><td></td><td></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"> <button aria-label="Copy the bibtex to the clipboard"> <iconify-icon icon="file-icons:bibtex" width="2em" height="2em"></iconify-icon> </button> </div></td></tr><tr class="Publicationsstyled__Publication-sc-997srn-2 IxZzp"><td><div aria-label="Team" style="width:32px;height:32px;background:conic-gradient(#984ea3 0deg 360deg);border-radius:5px"></div></td><td><span><a>Damien Robert</a><a>Hugo Raguet</a><a>Loic Landrieu</a></span><a href="https://hal.science/hal-04398319">Scalable 3D Panoptic Segmentation As Superpoint Graph Clustering. </a><span><i>11th International Conference on 3D Vision 2024 (3DV 2024)</i>, Mar 2024, Davos, Switzerland. <a target="_blank" href="https://dx.doi.org/10.1109/3dv62453.2024.00135">&#x27E8;10.1109/3dv62453.2024.00135&#x27E9;</a></span></td><td></td><td></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://www.doi.org/10.1109/3dv62453.2024.00135" aria-label="Document page using DOI"><iconify-icon icon="academicons:doi" width="2em" height="2em"></iconify-icon></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://hal.science/hal-04398319/document" aria-label="Main document in HAL"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 64C0 28.7 28.7 0 64 0L224 0l0 128c0 17.7 14.3 32 32 32l128 0 0 144-208 0c-35.3 0-64 28.7-64 64l0 144-48 0c-35.3 0-64-28.7-64-64L0 64zm384 64l-128 0L256 0 384 128zM176 352l32 0c30.9 0 56 25.1 56 56s-25.1 56-56 56l-16 0 0 32c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-48 0-80c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24l-16 0 0 48 16 0zm96-80l32 0c26.5 0 48 21.5 48 48l0 64c0 26.5-21.5 48-48 48l-32 0c-8.8 0-16-7.2-16-16l0-128c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16l0-64c0-8.8-7.2-16-16-16l-16 0 0 96 16 0zm80-112c0-8.8 7.2-16 16-16l48 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 32 32 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 48c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-64 0-64z"></path></svg></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"> <button aria-label="Copy the bibtex to the clipboard"> <iconify-icon icon="file-icons:bibtex" width="2em" height="2em"></iconify-icon> </button> </div></td></tr><tr class="Publicationsstyled__Publication-sc-997srn-2 IxZzp"><td><div aria-label="Team" style="width:32px;height:32px;background:conic-gradient(#984ea3 0deg 360deg);border-radius:5px"></div></td><td><span><a>Ekaterina Kalinicheva</a><a href="https://cv.archives-ouvertes.fr/loic-landrieu">Loic Landrieu</a><a href="https://cv.archives-ouvertes.fr/clement-mallet">Clément Mallet</a><a>Nesrine Chehata</a></span><a href="https://hal.science/hal-03718729">Multi-Layer Modeling of Dense Vegetation from Aerial LiDAR Scans. </a><span><i>IEEE/CVF Conference on Computer VIsion and Pattern Recognition Workshops</i>, Jun 2022, New Orleans, United States</span></td><td></td><td></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://hal.science/hal-03718729/document" aria-label="Main document in HAL"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 64C0 28.7 28.7 0 64 0L224 0l0 128c0 17.7 14.3 32 32 32l128 0 0 144-208 0c-35.3 0-64 28.7-64 64l0 144-48 0c-35.3 0-64-28.7-64-64L0 64zm384 64l-128 0L256 0 384 128zM176 352l32 0c30.9 0 56 25.1 56 56s-25.1 56-56 56l-16 0 0 32c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-48 0-80c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24l-16 0 0 48 16 0zm96-80l32 0c26.5 0 48 21.5 48 48l0 64c0 26.5-21.5 48-48 48l-32 0c-8.8 0-16-7.2-16-16l0-128c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16l0-64c0-8.8-7.2-16-16-16l-16 0 0 96 16 0zm80-112c0-8.8 7.2-16 16-16l48 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 32 32 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 48c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-64 0-64z"></path></svg></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"> <button aria-label="Copy the bibtex to the clipboard"> <iconify-icon icon="file-icons:bibtex" width="2em" height="2em"></iconify-icon> </button> </div></td></tr><tr class="Publicationsstyled__Publication-sc-997srn-2 IxZzp"><td><div aria-label="Team" style="width:32px;height:32px;background:conic-gradient(#984ea3 0deg 360deg);border-radius:5px"></div></td><td><span><a>Romain Loiseau</a><a href="https://cv.archives-ouvertes.fr/mathieu-aubry">Mathieu Aubry</a><a href="https://cv.archives-ouvertes.fr/loic-landrieu">Loic Landrieu</a></span><a href="https://hal.science/hal-03794797">Online Segmentation of LiDAR Sequences: Dataset and Algorithm. </a><span><i>European Conference on Computer Vision 2022</i>, Oct 2022, Tel-Aviv, Israel. <a target="_blank" href="https://dx.doi.org/10.1007/978-3-031-19839-7_18">&#x27E8;10.1007/978-3-031-19839-7_18&#x27E9;</a></span></td><td></td><td></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://www.doi.org/10.1007/978-3-031-19839-7_18" aria-label="Document page using DOI"><iconify-icon icon="academicons:doi" width="2em" height="2em"></iconify-icon></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"> <button aria-label="Copy the bibtex to the clipboard"> <iconify-icon icon="file-icons:bibtex" width="2em" height="2em"></iconify-icon> </button> </div></td></tr><tr class="Publicationsstyled__Publication-sc-997srn-2 IxZzp"><td><div aria-label="Team" style="width:32px;height:32px;background:conic-gradient(#e41a1c 0deg 180deg, #984ea3 180deg 360deg);border-radius:5px"></div></td><td><span><a href="https://cv.archives-ouvertes.fr/raphael-sulzer">R. Sulzer</a><a href="https://cv.archives-ouvertes.fr/loic-landrieu">Loic Landrieu</a><a href="https://cv.archives-ouvertes.fr/boulch-alexandre">Alexandre Boulch</a><a href="https://cv.archives-ouvertes.fr/renaud-marlet">Renaud Marlet</a><a>et al</a></span><a href="https://hal.science/hal-03575517">Deep Surface Reconstruction from Point Clouds with Visibility Information. </a><span><i>26th International Conference on Pattern Recognition (ICPR)</i>, Aug 2022, Montreal, Canada. pp.2415-2422, <a target="_blank" href="https://dx.doi.org/10.1109/ICPR56361.2022.9956560">&#x27E8;10.1109/ICPR56361.2022.9956560&#x27E9;</a></span></td><td></td><td></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://www.doi.org/10.1109/ICPR56361.2022.9956560" aria-label="Document page using DOI"><iconify-icon icon="academicons:doi" width="2em" height="2em"></iconify-icon></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://hal.science/hal-03575517/document" aria-label="Main document in HAL"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 64C0 28.7 28.7 0 64 0L224 0l0 128c0 17.7 14.3 32 32 32l128 0 0 144-208 0c-35.3 0-64 28.7-64 64l0 144-48 0c-35.3 0-64-28.7-64-64L0 64zm384 64l-128 0L256 0 384 128zM176 352l32 0c30.9 0 56 25.1 56 56s-25.1 56-56 56l-16 0 0 32c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-48 0-80c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24l-16 0 0 48 16 0zm96-80l32 0c26.5 0 48 21.5 48 48l0 64c0 26.5-21.5 48-48 48l-32 0c-8.8 0-16-7.2-16-16l0-128c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16l0-64c0-8.8-7.2-16-16-16l-16 0 0 96 16 0zm80-112c0-8.8 7.2-16 16-16l48 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 32 32 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 48c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-64 0-64z"></path></svg></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"> <button aria-label="Copy the bibtex to the clipboard"> <iconify-icon icon="file-icons:bibtex" width="2em" height="2em"></iconify-icon> </button> </div></td></tr><tr class="Publicationsstyled__Publication-sc-997srn-2 IxZzp"><td><div aria-label="Team" style="width:32px;height:32px;background:conic-gradient(#984ea3 0deg 180deg, #e41a1c 180deg 360deg);border-radius:5px"></div></td><td><span><a href="https://cv.archives-ouvertes.fr/loic-landrieu">Loic Landrieu</a><a href="https://cv.archives-ouvertes.fr/ewelina-rupnik">E Rupnik</a><a>S. Oude Elberink</a><a href="https://cv.archives-ouvertes.fr/clement-mallet">Clément Mallet</a><a>et al</a></span><a href="https://hal.science/hal-03713997">Preface: the 2022 edition of the XXIVth ISPRS Congress. </a><span><i>XXIVth ISPRS Congress</i>, Jun 2022, Nice, France. pp.1 - 5, <a target="_blank" href="https://dx.doi.org/10.5194/isprs-annals-v-3-2022-1-2022">&#x27E8;10.5194/isprs-annals-v-3-2022-1-2022&#x27E9;</a></span></td><td></td><td></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://www.doi.org/10.5194/isprs-annals-v-3-2022-1-2022" aria-label="Document page using DOI"><iconify-icon icon="academicons:doi" width="2em" height="2em"></iconify-icon></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://hal.science/hal-03713997/document" aria-label="Main document in HAL"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 64C0 28.7 28.7 0 64 0L224 0l0 128c0 17.7 14.3 32 32 32l128 0 0 144-208 0c-35.3 0-64 28.7-64 64l0 144-48 0c-35.3 0-64-28.7-64-64L0 64zm384 64l-128 0L256 0 384 128zM176 352l32 0c30.9 0 56 25.1 56 56s-25.1 56-56 56l-16 0 0 32c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-48 0-80c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24l-16 0 0 48 16 0zm96-80l32 0c26.5 0 48 21.5 48 48l0 64c0 26.5-21.5 48-48 48l-32 0c-8.8 0-16-7.2-16-16l0-128c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16l0-64c0-8.8-7.2-16-16-16l-16 0 0 96 16 0zm80-112c0-8.8 7.2-16 16-16l48 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 32 32 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 48c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-64 0-64z"></path></svg></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"> <button aria-label="Copy the bibtex to the clipboard"> <iconify-icon icon="file-icons:bibtex" width="2em" height="2em"></iconify-icon> </button> </div></td></tr><tr class="Publicationsstyled__Publication-sc-997srn-2 IxZzp"><td><div aria-label="Team" style="width:32px;height:32px;background:conic-gradient(#984ea3 0deg 360deg);border-radius:5px"></div></td><td><span><a>Romain Loiseau</a><a>Baptiste Bouvier</a><a>Yann Teytaut</a><a href="https://cv.archives-ouvertes.fr/elliot-vincent">Elliot Vincent</a><a>et al</a></span><a href="https://hal.science/hal-03794815">A Model You Can Hear: Audio Identification with Playable Prototypes. </a><span><i>ISMIR 2022 - 23rd International Society for Music Information Retrieval Conference</i>, Dec 2022, Bengaluru, India</span></td><td></td><td></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"> <button aria-label="Copy the bibtex to the clipboard"> <iconify-icon icon="file-icons:bibtex" width="2em" height="2em"></iconify-icon> </button> </div></td></tr><tr class="Publicationsstyled__Publication-sc-997srn-2 IxZzp"><td><div aria-label="Team" style="width:32px;height:32px;background:conic-gradient(#984ea3 0deg 360deg);border-radius:5px"></div></td><td><span><a>Vivien Sainte Fare Garnot</a><a href="https://cv.archives-ouvertes.fr/loic-landrieu">Loic Landrieu</a></span><a href="https://hal.science/hal-03500523">Panoptic Segmentation of Satellite Image Time Series with Convolutional Temporal Attention Networks. </a><span><i>International Conference on Computer Vision (ICCV)</i>, Oct 2021, Virtual, United States</span></td><td></td><td></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://hal.science/hal-03500523/document" aria-label="Main document in HAL"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 64C0 28.7 28.7 0 64 0L224 0l0 128c0 17.7 14.3 32 32 32l128 0 0 144-208 0c-35.3 0-64 28.7-64 64l0 144-48 0c-35.3 0-64-28.7-64-64L0 64zm384 64l-128 0L256 0 384 128zM176 352l32 0c30.9 0 56 25.1 56 56s-25.1 56-56 56l-16 0 0 32c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-48 0-80c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24l-16 0 0 48 16 0zm96-80l32 0c26.5 0 48 21.5 48 48l0 64c0 26.5-21.5 48-48 48l-32 0c-8.8 0-16-7.2-16-16l0-128c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16l0-64c0-8.8-7.2-16-16-16l-16 0 0 96 16 0zm80-112c0-8.8 7.2-16 16-16l48 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 32 32 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 48c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-64 0-64z"></path></svg></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"> <button aria-label="Copy the bibtex to the clipboard"> <iconify-icon icon="file-icons:bibtex" width="2em" height="2em"></iconify-icon> </button> </div></td></tr><tr class="Publicationsstyled__Publication-sc-997srn-2 IxZzp"><td><div aria-label="Team" style="width:32px;height:32px;background:conic-gradient(#984ea3 0deg 360deg);border-radius:5px"></div></td><td><span><a href="https://cv.archives-ouvertes.fr/loic-landrieu">Loic Landrieu</a><a>Vivien Sainte Fare Garnot</a></span><a href="https://hal.science/hal-03500516">Leveraging Class Hierarchies with Metric-Guided Prototype Learning. </a><span><i>British Machine Vision Conference (BMVC)</i>, Nov 2021, Virtual, United Kingdom</span></td><td></td><td></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://hal.science/hal-03500516/document" aria-label="Main document in HAL"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 64C0 28.7 28.7 0 64 0L224 0l0 128c0 17.7 14.3 32 32 32l128 0 0 144-208 0c-35.3 0-64 28.7-64 64l0 144-48 0c-35.3 0-64-28.7-64-64L0 64zm384 64l-128 0L256 0 384 128zM176 352l32 0c30.9 0 56 25.1 56 56s-25.1 56-56 56l-16 0 0 32c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-48 0-80c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24l-16 0 0 48 16 0zm96-80l32 0c26.5 0 48 21.5 48 48l0 64c0 26.5-21.5 48-48 48l-32 0c-8.8 0-16-7.2-16-16l0-128c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16l0-64c0-8.8-7.2-16-16-16l-16 0 0 96 16 0zm80-112c0-8.8 7.2-16 16-16l48 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 32 32 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 48c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-64 0-64z"></path></svg></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"> <button aria-label="Copy the bibtex to the clipboard"> <iconify-icon icon="file-icons:bibtex" width="2em" height="2em"></iconify-icon> </button> </div></td></tr><tr class="Publicationsstyled__Publication-sc-997srn-2 IxZzp"><td><div aria-label="Team" style="width:32px;height:32px;background:conic-gradient(#984ea3 0deg 360deg);border-radius:5px"></div></td><td><span><a>Romain Loiseau</a><a>Tom Monnier</a><a href="https://cv.archives-ouvertes.fr/mathieu-aubry">Mathieu Aubry</a><a>Loïc Landrieu</a></span><a href="https://hal.science/hal-03487329">Representing Shape Collections with Alignment-Aware Linear Models. </a><span><i>International Conference on 3D Vision 2021 (3DV 2021)</i>, Dec 2021, Londres (On-line), United Kingdom. <a target="_blank" href="https://dx.doi.org/10.1109/3dv53792.2021.00112">&#x27E8;10.1109/3dv53792.2021.00112&#x27E9;</a></span></td><td></td><td></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://www.doi.org/10.1109/3dv53792.2021.00112" aria-label="Document page using DOI"><iconify-icon icon="academicons:doi" width="2em" height="2em"></iconify-icon></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://hal.science/hal-03487329/document" aria-label="Main document in HAL"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 64C0 28.7 28.7 0 64 0L224 0l0 128c0 17.7 14.3 32 32 32l128 0 0 144-208 0c-35.3 0-64 28.7-64 64l0 144-48 0c-35.3 0-64-28.7-64-64L0 64zm384 64l-128 0L256 0 384 128zM176 352l32 0c30.9 0 56 25.1 56 56s-25.1 56-56 56l-16 0 0 32c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-48 0-80c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24l-16 0 0 48 16 0zm96-80l32 0c26.5 0 48 21.5 48 48l0 64c0 26.5-21.5 48-48 48l-32 0c-8.8 0-16-7.2-16-16l0-128c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16l0-64c0-8.8-7.2-16-16-16l-16 0 0 96 16 0zm80-112c0-8.8 7.2-16 16-16l48 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 32 32 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 48c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-64 0-64z"></path></svg></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"> <button aria-label="Copy the bibtex to the clipboard"> <iconify-icon icon="file-icons:bibtex" width="2em" height="2em"></iconify-icon> </button> </div></td></tr><tr class="Publicationsstyled__Publication-sc-997srn-2 IxZzp"><td><div aria-label="Team" style="width:32px;height:32px;background:conic-gradient(#984ea3 0deg 360deg);border-radius:5px"></div></td><td><span><a>Hugo Raguet</a><a href="https://cv.archives-ouvertes.fr/loic-landrieu">Loic Landrieu</a></span><a href="https://hal.science/hal-03481168">Cut-Pursuit Algorithm for Regularizing Nonsmooth Functionals with Graph Total Variation. </a><span><i>Thirty-sixth International Conference on Machine Learning ( ICM 2019 )L</i>, Jun 2019, Long Beach, United States</span></td><td></td><td></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://hal.science/hal-03481168/document" aria-label="Main document in HAL"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 64C0 28.7 28.7 0 64 0L224 0l0 128c0 17.7 14.3 32 32 32l128 0 0 144-208 0c-35.3 0-64 28.7-64 64l0 144-48 0c-35.3 0-64-28.7-64-64L0 64zm384 64l-128 0L256 0 384 128zM176 352l32 0c30.9 0 56 25.1 56 56s-25.1 56-56 56l-16 0 0 32c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-48 0-80c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24l-16 0 0 48 16 0zm96-80l32 0c26.5 0 48 21.5 48 48l0 64c0 26.5-21.5 48-48 48l-32 0c-8.8 0-16-7.2-16-16l0-128c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16l0-64c0-8.8-7.2-16-16-16l-16 0 0 96 16 0zm80-112c0-8.8 7.2-16 16-16l48 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 32 32 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 48c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-64 0-64z"></path></svg></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"> <button aria-label="Copy the bibtex to the clipboard"> <iconify-icon icon="file-icons:bibtex" width="2em" height="2em"></iconify-icon> </button> </div></td></tr><tr class="Publicationsstyled__Publication-sc-997srn-2 IxZzp"><td><div aria-label="Team" style="width:32px;height:32px;background:conic-gradient(#984ea3 0deg 360deg);border-radius:5px"></div></td><td><span><a href="https://cv.archives-ouvertes.fr/loic-landrieu">Loic Landrieu</a><a>Simonovsky Martin</a></span><a href="https://hal.science/hal-01939229">Segmentation Sémantique à Grande Echelle par Graphe de Superpoints,Large-scale Point Cloud Semantic Segmentation with Superpoint Graphs. </a><span><i>RFIAP</i>, Jun 2018, Marne-la-Vallée, France</span></td><td></td><td></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://hal.science/hal-01939229/document" aria-label="Main document in HAL"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 64C0 28.7 28.7 0 64 0L224 0l0 128c0 17.7 14.3 32 32 32l128 0 0 144-208 0c-35.3 0-64 28.7-64 64l0 144-48 0c-35.3 0-64-28.7-64-64L0 64zm384 64l-128 0L256 0 384 128zM176 352l32 0c30.9 0 56 25.1 56 56s-25.1 56-56 56l-16 0 0 32c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-48 0-80c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24l-16 0 0 48 16 0zm96-80l32 0c26.5 0 48 21.5 48 48l0 64c0 26.5-21.5 48-48 48l-32 0c-8.8 0-16-7.2-16-16l0-128c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16l0-64c0-8.8-7.2-16-16-16l-16 0 0 96 16 0zm80-112c0-8.8 7.2-16 16-16l48 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 32 32 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 48c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-64 0-64z"></path></svg></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"> <button aria-label="Copy the bibtex to the clipboard"> <iconify-icon icon="file-icons:bibtex" width="2em" height="2em"></iconify-icon> </button> </div></td></tr></tbody></table></div><div id="pubACTI"><h2> <!-- -->International conferences<!-- --> </h2><table class="Publicationsstyled__StyledPublicationList-sc-997srn-1 bJhdgp"><thead></thead><tbody><tr class="Publicationsstyled__Publication-sc-997srn-2 IxZzp"><td><div aria-label="Team" style="width:32px;height:32px;background:conic-gradient(#984ea3 0deg 360deg);border-radius:5px"></div></td><td><span><a href="https://cv.archives-ouvertes.fr/gastruc">Guillaume Astruc</a><a href="https://cv.archives-ouvertes.fr/nicolas-gonthier">Nicolas Gonthier</a><a href="https://cv.archives-ouvertes.fr/clement-mallet">Clément Mallet</a><a href="https://cv.archives-ouvertes.fr/loic-landrieu">Loic Landrieu</a></span><a href="https://hal.science/hal-04984436">AnySat: An Earth Observation Model for Any Resolutions,Scales,and Modalities. </a><span><i>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</i>, Jun 2025, Nashville (Tennessee), United States</span></td><td></td><td></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"> <button aria-label="Copy the bibtex to the clipboard"> <iconify-icon icon="file-icons:bibtex" width="2em" height="2em"></iconify-icon> </button> </div></td></tr><tr class="Publicationsstyled__Publication-sc-997srn-2 IxZzp"><td><div aria-label="Team" style="width:32px;height:32px;background:conic-gradient(#984ea3 0deg 360deg);border-radius:5px"></div></td><td><span><a>Abhishek Kuriyal</a><a href="https://cv.archives-ouvertes.fr/elliot-vincent">Elliot Vincent</a><a href="https://cv.archives-ouvertes.fr/mathieu-aubry">Mathieu Aubry</a><a href="https://cv.archives-ouvertes.fr/loic-landrieu">Loic Landrieu</a></span><a href="https://hal.science/hal-05121438">CoDEx: Combining Domain Expertise for Spatial Generalization in Satellite Image Analysis. </a><span><i>CVPR 2025 EarthVision Workshop - The IEEE/CVF Conference on Computer Vision and Pattern Recognition</i>, Jun 2025, Nashville (Tennessee), United States. pp.2194-2203</span></td><td></td><td></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://hal.science/hal-05121438/document" aria-label="Main document in HAL"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 64C0 28.7 28.7 0 64 0L224 0l0 128c0 17.7 14.3 32 32 32l128 0 0 144-208 0c-35.3 0-64 28.7-64 64l0 144-48 0c-35.3 0-64-28.7-64-64L0 64zm384 64l-128 0L256 0 384 128zM176 352l32 0c30.9 0 56 25.1 56 56s-25.1 56-56 56l-16 0 0 32c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-48 0-80c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24l-16 0 0 48 16 0zm96-80l32 0c26.5 0 48 21.5 48 48l0 64c0 26.5-21.5 48-48 48l-32 0c-8.8 0-16-7.2-16-16l0-128c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16l0-64c0-8.8-7.2-16-16-16l-16 0 0 96 16 0zm80-112c0-8.8 7.2-16 16-16l48 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 32 32 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 48c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-64 0-64z"></path></svg></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"> <button aria-label="Copy the bibtex to the clipboard"> <iconify-icon icon="file-icons:bibtex" width="2em" height="2em"></iconify-icon> </button> </div></td></tr><tr class="Publicationsstyled__Publication-sc-997srn-2 IxZzp"><td><div aria-label="Team" style="width:32px;height:32px;background:conic-gradient(#984ea3 0deg 360deg);border-radius:5px"></div></td><td><span><a href="https://cv.archives-ouvertes.fr/gastruc">Guillaume Astruc</a><a href="https://cv.archives-ouvertes.fr/nicolas-gonthier">Nicolas Gonthier</a><a>Clément Mallet</a><a href="https://cv.archives-ouvertes.fr/loic-landrieu">Loic Landrieu</a></span><a href="https://hal.science/hal-04556598">OmniSat: Self-Supervised Modality Fusion for Earth Observation. </a><span><i>ECCV</i>, 2024, Milan (Italie), Italy</span></td><td></td><td></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://hal.science/hal-04556598/document" aria-label="Main document in HAL"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 64C0 28.7 28.7 0 64 0L224 0l0 128c0 17.7 14.3 32 32 32l128 0 0 144-208 0c-35.3 0-64 28.7-64 64l0 144-48 0c-35.3 0-64-28.7-64-64L0 64zm384 64l-128 0L256 0 384 128zM176 352l32 0c30.9 0 56 25.1 56 56s-25.1 56-56 56l-16 0 0 32c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-48 0-80c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24l-16 0 0 48 16 0zm96-80l32 0c26.5 0 48 21.5 48 48l0 64c0 26.5-21.5 48-48 48l-32 0c-8.8 0-16-7.2-16-16l0-128c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16l0-64c0-8.8-7.2-16-16-16l-16 0 0 96 16 0zm80-112c0-8.8 7.2-16 16-16l48 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 32 32 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 48c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-64 0-64z"></path></svg></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"> <button aria-label="Copy the bibtex to the clipboard"> <iconify-icon icon="file-icons:bibtex" width="2em" height="2em"></iconify-icon> </button> </div></td></tr><tr class="Publicationsstyled__Publication-sc-997srn-2 IxZzp"><td><div aria-label="Team" style="width:32px;height:32px;background:conic-gradient(#984ea3 0deg 360deg);border-radius:5px"></div></td><td><span><a>Sidi Wu</a><a>Yizi Chen</a><a>Samuel Mermet</a><a>Lorenz Hurni</a><a>et al</a></span><a href="https://hal.science/hal-04808719">StegoGAN: Leveraging Steganography for Non-Bijective Image-to-Image Translation. </a><span><i>IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i>, Jun 2024, Seattle, United States</span></td><td></td><td></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://hal.science/hal-04808719/document" aria-label="Main document in HAL"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 64C0 28.7 28.7 0 64 0L224 0l0 128c0 17.7 14.3 32 32 32l128 0 0 144-208 0c-35.3 0-64 28.7-64 64l0 144-48 0c-35.3 0-64-28.7-64-64L0 64zm384 64l-128 0L256 0 384 128zM176 352l32 0c30.9 0 56 25.1 56 56s-25.1 56-56 56l-16 0 0 32c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-48 0-80c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24l-16 0 0 48 16 0zm96-80l32 0c26.5 0 48 21.5 48 48l0 64c0 26.5-21.5 48-48 48l-32 0c-8.8 0-16-7.2-16-16l0-128c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16l0-64c0-8.8-7.2-16-16-16l-16 0 0 96 16 0zm80-112c0-8.8 7.2-16 16-16l48 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 32 32 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 48c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-64 0-64z"></path></svg></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"> <button aria-label="Copy the bibtex to the clipboard"> <iconify-icon icon="file-icons:bibtex" width="2em" height="2em"></iconify-icon> </button> </div></td></tr><tr class="Publicationsstyled__Publication-sc-997srn-2 IxZzp"><td><div aria-label="Team" style="width:32px;height:32px;background:conic-gradient(#984ea3 0deg 360deg);border-radius:5px"></div></td><td><span><a href="https://cv.archives-ouvertes.fr/yohann-perron">Yohann Perron</a><a>Vladyslav Sydorov</a><a>Adam P. Wijker</a><a>Damian Evans</a><a>et al</a></span><a href="https://hal.science/hal-04917310">Archaeoscape: Bringing Aerial Laser Scanning Archaeology to the Deep Learning Era. </a><span><i>NeurIPS, 2024, Dataset and Benchmark track</i>, Dec 2024, Vancouver (BC), Canada</span></td><td></td><td></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://hal.science/hal-04917310/document" aria-label="Main document in HAL"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 64C0 28.7 28.7 0 64 0L224 0l0 128c0 17.7 14.3 32 32 32l128 0 0 144-208 0c-35.3 0-64 28.7-64 64l0 144-48 0c-35.3 0-64-28.7-64-64L0 64zm384 64l-128 0L256 0 384 128zM176 352l32 0c30.9 0 56 25.1 56 56s-25.1 56-56 56l-16 0 0 32c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-48 0-80c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24l-16 0 0 48 16 0zm96-80l32 0c26.5 0 48 21.5 48 48l0 64c0 26.5-21.5 48-48 48l-32 0c-8.8 0-16-7.2-16-16l0-128c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16l0-64c0-8.8-7.2-16-16-16l-16 0 0 96 16 0zm80-112c0-8.8 7.2-16 16-16l48 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 32 32 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 48c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-64 0-64z"></path></svg></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"> <button aria-label="Copy the bibtex to the clipboard"> <iconify-icon icon="file-icons:bibtex" width="2em" height="2em"></iconify-icon> </button> </div></td></tr><tr class="Publicationsstyled__Publication-sc-997srn-2 IxZzp"><td><div aria-label="Team" style="width:32px;height:32px;background:conic-gradient(#984ea3 0deg 360deg);border-radius:5px"></div></td><td><span><a>Romain Loiseau</a><a href="https://cv.archives-ouvertes.fr/elliot-vincent">Elliot Vincent</a><a href="https://cv.archives-ouvertes.fr/mathieu-aubry">Mathieu Aubry</a><a>Loic Landrieu</a></span><a href="https://hal.science/hal-04135416">Learnable Earth Parser: Discovering 3D Prototypes in Aerial Scans. </a><span><i>CVPR 2024 - The IEEE/CVF Conference on Computer Vision and Pattern Recognition</i>, Jun 2024, Seattle, United States</span></td><td></td><td></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"> <button aria-label="Copy the bibtex to the clipboard"> <iconify-icon icon="file-icons:bibtex" width="2em" height="2em"></iconify-icon> </button> </div></td></tr><tr class="Publicationsstyled__Publication-sc-997srn-2 IxZzp"><td><div aria-label="Team" style="width:32px;height:32px;background:conic-gradient(#984ea3 0deg 360deg);border-radius:5px"></div></td><td><span><a>Damien Robert</a><a>Hugo Raguet</a><a>Loic Landrieu</a></span><a href="https://hal.science/hal-04140052">Efficient 3D Semantic Segmentation with Superpoint Transformer. </a><span><i>International Conference on Computer Vision</i>, CVR, IEEE, Oct 2023, Paris, France. pp.17195-17204, <a target="_blank" href="https://dx.doi.org/10.1109/iccv51070.2023.01577">&#x27E8;10.1109/iccv51070.2023.01577&#x27E9;</a></span></td><td></td><td></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://www.doi.org/10.1109/iccv51070.2023.01577" aria-label="Document page using DOI"><iconify-icon icon="academicons:doi" width="2em" height="2em"></iconify-icon></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://hal.science/hal-04140052/document" aria-label="Main document in HAL"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 64C0 28.7 28.7 0 64 0L224 0l0 128c0 17.7 14.3 32 32 32l128 0 0 144-208 0c-35.3 0-64 28.7-64 64l0 144-48 0c-35.3 0-64-28.7-64-64L0 64zm384 64l-128 0L256 0 384 128zM176 352l32 0c30.9 0 56 25.1 56 56s-25.1 56-56 56l-16 0 0 32c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-48 0-80c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24l-16 0 0 48 16 0zm96-80l32 0c26.5 0 48 21.5 48 48l0 64c0 26.5-21.5 48-48 48l-32 0c-8.8 0-16-7.2-16-16l0-128c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16l0-64c0-8.8-7.2-16-16-16l-16 0 0 96 16 0zm80-112c0-8.8 7.2-16 16-16l48 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 32 32 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 48c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-64 0-64z"></path></svg></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"> <button aria-label="Copy the bibtex to the clipboard"> <iconify-icon icon="file-icons:bibtex" width="2em" height="2em"></iconify-icon> </button> </div></td></tr><tr class="Publicationsstyled__Publication-sc-997srn-2 IxZzp"><td><div aria-label="Team" style="width:32px;height:32px;background:conic-gradient(#984ea3 0deg 360deg);border-radius:5px"></div></td><td><span><a href="https://cv.archives-ouvertes.fr/anatol-garioud">Anatol Garioud</a><a href="https://cv.archives-ouvertes.fr/nicolas-gonthier">Nicolas Gonthier</a><a href="https://cv.archives-ouvertes.fr/loic-landrieu">Loic Landrieu</a><a>Apolline De Wit</a><a>et al</a></span><a href="https://hal.science/hal-04328458">FLAIR: a Country-Scale Land Cover Semantic Segmentation Dataset From Multi-Source Optical Imagery. </a><span><i>NeurIPS Dataset and Benchmark</i>, 2023, New Orleans, United States</span></td><td></td><td></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://hal.science/hal-04328458/document" aria-label="Main document in HAL"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 64C0 28.7 28.7 0 64 0L224 0l0 128c0 17.7 14.3 32 32 32l128 0 0 144-208 0c-35.3 0-64 28.7-64 64l0 144-48 0c-35.3 0-64-28.7-64-64L0 64zm384 64l-128 0L256 0 384 128zM176 352l32 0c30.9 0 56 25.1 56 56s-25.1 56-56 56l-16 0 0 32c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-48 0-80c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24l-16 0 0 48 16 0zm96-80l32 0c26.5 0 48 21.5 48 48l0 64c0 26.5-21.5 48-48 48l-32 0c-8.8 0-16-7.2-16-16l0-128c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16l0-64c0-8.8-7.2-16-16-16l-16 0 0 96 16 0zm80-112c0-8.8 7.2-16 16-16l48 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 32 32 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 48c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-64 0-64z"></path></svg></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"> <button aria-label="Copy the bibtex to the clipboard"> <iconify-icon icon="file-icons:bibtex" width="2em" height="2em"></iconify-icon> </button> </div></td></tr><tr class="Publicationsstyled__Publication-sc-997srn-2 IxZzp"><td><div aria-label="Team" style="width:32px;height:32px;background:conic-gradient(#984ea3 0deg 180deg, #e41a1c 180deg 360deg);border-radius:5px"></div></td><td><span><a>Damien Robert</a><a>Bruno Vallet</a><a>Loic Landrieu</a></span><a href="https://hal.science/hal-03824190">Learning Multi-View Aggregation In the Wild for Large-Scale 3D Semantic Segmentation. </a><span><i>2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</i>, Jun 2022, New Orleans, United States. pp.5565-5574, <a target="_blank" href="https://dx.doi.org/10.1109/CVPR52688.2022.00549">&#x27E8;10.1109/CVPR52688.2022.00549&#x27E9;</a></span></td><td></td><td></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://www.doi.org/10.1109/CVPR52688.2022.00549" aria-label="Document page using DOI"><iconify-icon icon="academicons:doi" width="2em" height="2em"></iconify-icon></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://hal.science/hal-03824190/document" aria-label="Main document in HAL"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 64C0 28.7 28.7 0 64 0L224 0l0 128c0 17.7 14.3 32 32 32l128 0 0 144-208 0c-35.3 0-64 28.7-64 64l0 144-48 0c-35.3 0-64-28.7-64-64L0 64zm384 64l-128 0L256 0 384 128zM176 352l32 0c30.9 0 56 25.1 56 56s-25.1 56-56 56l-16 0 0 32c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-48 0-80c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24l-16 0 0 48 16 0zm96-80l32 0c26.5 0 48 21.5 48 48l0 64c0 26.5-21.5 48-48 48l-32 0c-8.8 0-16-7.2-16-16l0-128c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16l0-64c0-8.8-7.2-16-16-16l-16 0 0 96 16 0zm80-112c0-8.8 7.2-16 16-16l48 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 32 32 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 48c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-64 0-64z"></path></svg></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"> <button aria-label="Copy the bibtex to the clipboard"> <iconify-icon icon="file-icons:bibtex" width="2em" height="2em"></iconify-icon> </button> </div></td></tr><tr class="Publicationsstyled__Publication-sc-997srn-2 IxZzp"><td><div aria-label="Team" style="width:32px;height:32px;background:conic-gradient(#984ea3 0deg 360deg);border-radius:5px"></div></td><td><span><a>Vivien Sainte Fare Garnot</a><a href="https://cv.archives-ouvertes.fr/loic-landrieu">Loic Landrieu</a></span><a href="https://hal.science/hal-03016094">Lightweight temporal self-Attention for classifying satellite images time series. </a><span><i>Workshop on Advanced Analytics and Learning on Temporal Data</i>, Sep 2020, en ligne, Belgium</span></td><td></td><td></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://hal.science/hal-03016094/document" aria-label="Main document in HAL"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 64C0 28.7 28.7 0 64 0L224 0l0 128c0 17.7 14.3 32 32 32l128 0 0 144-208 0c-35.3 0-64 28.7-64 64l0 144-48 0c-35.3 0-64-28.7-64-64L0 64zm384 64l-128 0L256 0 384 128zM176 352l32 0c30.9 0 56 25.1 56 56s-25.1 56-56 56l-16 0 0 32c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-48 0-80c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24l-16 0 0 48 16 0zm96-80l32 0c26.5 0 48 21.5 48 48l0 64c0 26.5-21.5 48-48 48l-32 0c-8.8 0-16-7.2-16-16l0-128c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16l0-64c0-8.8-7.2-16-16-16l-16 0 0 96 16 0zm80-112c0-8.8 7.2-16 16-16l48 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 32 32 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 48c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-64 0-64z"></path></svg></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"> <button aria-label="Copy the bibtex to the clipboard"> <iconify-icon icon="file-icons:bibtex" width="2em" height="2em"></iconify-icon> </button> </div></td></tr><tr class="Publicationsstyled__Publication-sc-997srn-2 IxZzp"><td><div aria-label="Team" style="width:32px;height:32px;background:conic-gradient(#984ea3 0deg 360deg);border-radius:5px"></div></td><td><span><a>Thomas Chaton</a><a>Nicolas Chaulet</a><a>Sofiane Horache</a><a href="https://cv.archives-ouvertes.fr/loic-landrieu">Loic Landrieu</a></span><a href="https://hal.science/hal-03013190">Torch-Points3D: A modular multi-task framework for reproducible deep learning on 3D point clouds. </a><span><i>3DV 2020 - International Conference on 3D Vision</i>, Nov 2020, online, Japan</span></td><td></td><td></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://hal.science/hal-03013190/document" aria-label="Main document in HAL"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 64C0 28.7 28.7 0 64 0L224 0l0 128c0 17.7 14.3 32 32 32l128 0 0 144-208 0c-35.3 0-64 28.7-64 64l0 144-48 0c-35.3 0-64-28.7-64-64L0 64zm384 64l-128 0L256 0 384 128zM176 352l32 0c30.9 0 56 25.1 56 56s-25.1 56-56 56l-16 0 0 32c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-48 0-80c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24l-16 0 0 48 16 0zm96-80l32 0c26.5 0 48 21.5 48 48l0 64c0 26.5-21.5 48-48 48l-32 0c-8.8 0-16-7.2-16-16l0-128c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16l0-64c0-8.8-7.2-16-16-16l-16 0 0 96 16 0zm80-112c0-8.8 7.2-16 16-16l48 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 32 32 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 48c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-64 0-64z"></path></svg></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"> <button aria-label="Copy the bibtex to the clipboard"> <iconify-icon icon="file-icons:bibtex" width="2em" height="2em"></iconify-icon> </button> </div></td></tr><tr class="Publicationsstyled__Publication-sc-997srn-2 IxZzp"><td><div aria-label="Team" style="width:32px;height:32px;background:conic-gradient(#984ea3 0deg 360deg);border-radius:5px"></div></td><td><span><a>Vivien Sainte Fare Garnot</a><a>Loic Landrieu</a><a>Sebastien Giordano</a><a>Nesrine Chehata</a></span><a href="https://hal.science/hal-02879223">Satellite Image Time Series Classification with Pixel-Set Encoders and Temporal Self-Attention. </a><span><i>CVPR 2020</i>, Jun 2020, Seattle, United States</span></td><td></td><td></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://hal.science/hal-02879223/document" aria-label="Main document in HAL"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 64C0 28.7 28.7 0 64 0L224 0l0 128c0 17.7 14.3 32 32 32l128 0 0 144-208 0c-35.3 0-64 28.7-64 64l0 144-48 0c-35.3 0-64-28.7-64-64L0 64zm384 64l-128 0L256 0 384 128zM176 352l32 0c30.9 0 56 25.1 56 56s-25.1 56-56 56l-16 0 0 32c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-48 0-80c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24l-16 0 0 48 16 0zm96-80l32 0c26.5 0 48 21.5 48 48l0 64c0 26.5-21.5 48-48 48l-32 0c-8.8 0-16-7.2-16-16l0-128c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16l0-64c0-8.8-7.2-16-16-16l-16 0 0 96 16 0zm80-112c0-8.8 7.2-16 16-16l48 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 32 32 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 48c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-64 0-64z"></path></svg></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"> <button aria-label="Copy the bibtex to the clipboard"> <iconify-icon icon="file-icons:bibtex" width="2em" height="2em"></iconify-icon> </button> </div></td></tr><tr class="Publicationsstyled__Publication-sc-997srn-2 IxZzp"><td><div aria-label="Team" style="width:32px;height:32px;background:conic-gradient(#984ea3 0deg 180deg, #e41a1c 180deg 360deg);border-radius:5px"></div></td><td><span><a href="https://cv.archives-ouvertes.fr/loic-landrieu">Loic Landrieu</a><a href="https://cv.archives-ouvertes.fr/mohamed-boussaha">Mohamed Boussaha</a></span><a href="https://hal.science/hal-03016113">Point Cloud Oversegmentation with Graph-Structured Deep Metric Learning. </a><span><i>CVPR</i>, 2019, Long Beach, France</span></td><td></td><td></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://hal.science/hal-03016113/document" aria-label="Main document in HAL"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 64C0 28.7 28.7 0 64 0L224 0l0 128c0 17.7 14.3 32 32 32l128 0 0 144-208 0c-35.3 0-64 28.7-64 64l0 144-48 0c-35.3 0-64-28.7-64-64L0 64zm384 64l-128 0L256 0 384 128zM176 352l32 0c30.9 0 56 25.1 56 56s-25.1 56-56 56l-16 0 0 32c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-48 0-80c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24l-16 0 0 48 16 0zm96-80l32 0c26.5 0 48 21.5 48 48l0 64c0 26.5-21.5 48-48 48l-32 0c-8.8 0-16-7.2-16-16l0-128c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16l0-64c0-8.8-7.2-16-16-16l-16 0 0 96 16 0zm80-112c0-8.8 7.2-16 16-16l48 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 32 32 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 48c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-64 0-64z"></path></svg></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"> <button aria-label="Copy the bibtex to the clipboard"> <iconify-icon icon="file-icons:bibtex" width="2em" height="2em"></iconify-icon> </button> </div></td></tr><tr class="Publicationsstyled__Publication-sc-997srn-2 IxZzp"><td><div aria-label="Team" style="width:32px;height:32px;background:conic-gradient(#984ea3 0deg 180deg, #e41a1c 180deg 360deg);border-radius:5px"></div></td><td><span><a href="https://cv.archives-ouvertes.fr/loic-landrieu">Loic Landrieu</a><a href="https://cv.archives-ouvertes.fr/mohamed-boussaha">Mohamed Boussaha</a></span><a href="https://hal.science/hal-03016114">Supervized segmentation with graph-structured deep metric learning. </a><span><i>ICML Workshop on Learning and Reasoning with Graph-Structured Representations</i>, Jun 2019, Long Beach (CA), United States</span></td><td></td><td></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://hal.science/hal-03016114/document" aria-label="Main document in HAL"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 64C0 28.7 28.7 0 64 0L224 0l0 128c0 17.7 14.3 32 32 32l128 0 0 144-208 0c-35.3 0-64 28.7-64 64l0 144-48 0c-35.3 0-64-28.7-64-64L0 64zm384 64l-128 0L256 0 384 128zM176 352l32 0c30.9 0 56 25.1 56 56s-25.1 56-56 56l-16 0 0 32c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-48 0-80c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24l-16 0 0 48 16 0zm96-80l32 0c26.5 0 48 21.5 48 48l0 64c0 26.5-21.5 48-48 48l-32 0c-8.8 0-16-7.2-16-16l0-128c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16l0-64c0-8.8-7.2-16-16-16l-16 0 0 96 16 0zm80-112c0-8.8 7.2-16 16-16l48 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 32 32 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 48c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-64 0-64z"></path></svg></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"> <button aria-label="Copy the bibtex to the clipboard"> <iconify-icon icon="file-icons:bibtex" width="2em" height="2em"></iconify-icon> </button> </div></td></tr><tr class="Publicationsstyled__Publication-sc-997srn-2 IxZzp"><td><div aria-label="Team" style="width:32px;height:32px;background:conic-gradient(#984ea3 0deg 360deg);border-radius:5px"></div></td><td><span><a>Vivien Sainte Fare Garnot</a><a href="https://cv.archives-ouvertes.fr/loic-landrieu">Loic Landrieu</a><a href="https://cv.archives-ouvertes.fr/sebastien-giordano">Sébastien Giordano</a><a>N. Chehata</a></span><a href="https://hal.science/hal-02386701">Time-Space Tradeoff in Deep Learning Models for Crop Classification on Satellite Multi-Spectral Image Time Series. </a><span><i>IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium</i>, Jul 2019, Yokohama, Japan. pp.6247-6250, <a target="_blank" href="https://dx.doi.org/10.1109/IGARSS.2019.8900517">&#x27E8;10.1109/IGARSS.2019.8900517&#x27E9;</a></span></td><td></td><td></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://www.doi.org/10.1109/IGARSS.2019.8900517" aria-label="Document page using DOI"><iconify-icon icon="academicons:doi" width="2em" height="2em"></iconify-icon></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://hal.science/hal-02386701/document" aria-label="Main document in HAL"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 64C0 28.7 28.7 0 64 0L224 0l0 128c0 17.7 14.3 32 32 32l128 0 0 144-208 0c-35.3 0-64 28.7-64 64l0 144-48 0c-35.3 0-64-28.7-64-64L0 64zm384 64l-128 0L256 0 384 128zM176 352l32 0c30.9 0 56 25.1 56 56s-25.1 56-56 56l-16 0 0 32c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-48 0-80c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24l-16 0 0 48 16 0zm96-80l32 0c26.5 0 48 21.5 48 48l0 64c0 26.5-21.5 48-48 48l-32 0c-8.8 0-16-7.2-16-16l0-128c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16l0-64c0-8.8-7.2-16-16-16l-16 0 0 96 16 0zm80-112c0-8.8 7.2-16 16-16l48 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 32 32 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 48c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-64 0-64z"></path></svg></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"> <button aria-label="Copy the bibtex to the clipboard"> <iconify-icon icon="file-icons:bibtex" width="2em" height="2em"></iconify-icon> </button> </div></td></tr><tr class="Publicationsstyled__Publication-sc-997srn-2 IxZzp"><td><div aria-label="Team" style="width:32px;height:32px;background:conic-gradient(#984ea3 0deg 360deg);border-radius:5px"></div></td><td><span><a>Raguet Hugo</a><a href="https://cv.archives-ouvertes.fr/loic-landrieu">Loic Landrieu</a></span><a href="https://hal.science/hal-03016110">Parallel Cut Pursuit For Minimization of the Graph Total Variation. </a><span><i>ICML Workshop on Learning and Reasoning with Graph-Structured Representations</i>, Jun 2019, Long Beach (CA), United States</span></td><td></td><td></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://hal.science/hal-03016110/document" aria-label="Main document in HAL"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 64C0 28.7 28.7 0 64 0L224 0l0 128c0 17.7 14.3 32 32 32l128 0 0 144-208 0c-35.3 0-64 28.7-64 64l0 144-48 0c-35.3 0-64-28.7-64-64L0 64zm384 64l-128 0L256 0 384 128zM176 352l32 0c30.9 0 56 25.1 56 56s-25.1 56-56 56l-16 0 0 32c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-48 0-80c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24l-16 0 0 48 16 0zm96-80l32 0c26.5 0 48 21.5 48 48l0 64c0 26.5-21.5 48-48 48l-32 0c-8.8 0-16-7.2-16-16l0-128c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16l0-64c0-8.8-7.2-16-16-16l-16 0 0 96 16 0zm80-112c0-8.8 7.2-16 16-16l48 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 32 32 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 48c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-64 0-64z"></path></svg></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"> <button aria-label="Copy the bibtex to the clipboard"> <iconify-icon icon="file-icons:bibtex" width="2em" height="2em"></iconify-icon> </button> </div></td></tr><tr class="Publicationsstyled__Publication-sc-997srn-2 IxZzp"><td><div aria-label="Team" style="width:32px;height:32px;background:conic-gradient(#984ea3 0deg 360deg);border-radius:5px"></div></td><td><span><a href="https://cv.archives-ouvertes.fr/loic-landrieu">Loic Landrieu</a><a>Simonovsky Martin</a></span><a href="https://hal.science/hal-01801186">Large-scale Point Cloud Semantic Segmentation with Superpoint Graphs. </a><span><i>2018 IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2018)</i>, Jun 2018, Salt Lake City, United States</span></td><td></td><td></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://hal.science/hal-01801186/document" aria-label="Main document in HAL"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 64C0 28.7 28.7 0 64 0L224 0l0 128c0 17.7 14.3 32 32 32l128 0 0 144-208 0c-35.3 0-64 28.7-64 64l0 144-48 0c-35.3 0-64-28.7-64-64L0 64zm384 64l-128 0L256 0 384 128zM176 352l32 0c30.9 0 56 25.1 56 56s-25.1 56-56 56l-16 0 0 32c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-48 0-80c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24l-16 0 0 48 16 0zm96-80l32 0c26.5 0 48 21.5 48 48l0 64c0 26.5-21.5 48-48 48l-32 0c-8.8 0-16-7.2-16-16l0-128c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16l0-64c0-8.8-7.2-16-16-16l-16 0 0 96 16 0zm80-112c0-8.8 7.2-16 16-16l48 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 32 32 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 48c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-64 0-64z"></path></svg></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"> <button aria-label="Copy the bibtex to the clipboard"> <iconify-icon icon="file-icons:bibtex" width="2em" height="2em"></iconify-icon> </button> </div></td></tr><tr class="Publicationsstyled__Publication-sc-997srn-2 IxZzp"><td><div aria-label="Team" style="width:32px;height:32px;background:conic-gradient(#984ea3 0deg 360deg);border-radius:5px"></div></td><td><span><a href="https://cv.archives-ouvertes.fr/loic-landrieu">Loic Landrieu</a><a>Martin Simonovsky</a></span><a href="https://hal.science/hal-02545223">Large-scale Point Cloud Semantic Segmentation with Superpoint Graphs. </a><span><i>CVPR 2018, IEEE Conference on Computer Vision and Pattern Recognition</i>, Jun 2018, Salt Lake City, France</span></td><td></td><td></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://hal.science/hal-02545223/document" aria-label="Main document in HAL"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 64C0 28.7 28.7 0 64 0L224 0l0 128c0 17.7 14.3 32 32 32l128 0 0 144-208 0c-35.3 0-64 28.7-64 64l0 144-48 0c-35.3 0-64-28.7-64-64L0 64zm384 64l-128 0L256 0 384 128zM176 352l32 0c30.9 0 56 25.1 56 56s-25.1 56-56 56l-16 0 0 32c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-48 0-80c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24l-16 0 0 48 16 0zm96-80l32 0c26.5 0 48 21.5 48 48l0 64c0 26.5-21.5 48-48 48l-32 0c-8.8 0-16-7.2-16-16l0-128c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16l0-64c0-8.8-7.2-16-16-16l-16 0 0 96 16 0zm80-112c0-8.8 7.2-16 16-16l48 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 32 32 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 48c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-64 0-64z"></path></svg></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"> <button aria-label="Copy the bibtex to the clipboard"> <iconify-icon icon="file-icons:bibtex" width="2em" height="2em"></iconify-icon> </button> </div></td></tr><tr class="Publicationsstyled__Publication-sc-997srn-2 IxZzp"><td><div aria-label="Team" style="width:32px;height:32px;background:conic-gradient(#e41a1c 0deg 180deg, #984ea3 180deg 360deg);border-radius:5px"></div></td><td><span><a href="https://cv.archives-ouvertes.fr/stephane-guinard">Stéphane Guinard</a><a href="https://cv.archives-ouvertes.fr/loic-landrieu">Loic Landrieu</a></span><a href="https://hal.science/hal-01497548">Weakly supervised segmentation-aided classification of urban scenes from 3D LiDAR point clouds,Pré-segmentation pour la classification faiblement supervisée de scènes urbaines à partir de nuages de points 3D LIDAR. </a><span><i>ISPRS Workshop 2017</i>, Jun 2017, Hannover, Germany</span></td><td></td><td></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://hal.science/hal-01497548/document" aria-label="Main document in HAL"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 64C0 28.7 28.7 0 64 0L224 0l0 128c0 17.7 14.3 32 32 32l128 0 0 144-208 0c-35.3 0-64 28.7-64 64l0 144-48 0c-35.3 0-64-28.7-64-64L0 64zm384 64l-128 0L256 0 384 128zM176 352l32 0c30.9 0 56 25.1 56 56s-25.1 56-56 56l-16 0 0 32c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-48 0-80c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24l-16 0 0 48 16 0zm96-80l32 0c26.5 0 48 21.5 48 48l0 64c0 26.5-21.5 48-48 48l-32 0c-8.8 0-16-7.2-16-16l0-128c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16l0-64c0-8.8-7.2-16-16-16l-16 0 0 96 16 0zm80-112c0-8.8 7.2-16 16-16l48 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 32 32 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 48c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-64 0-64z"></path></svg></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"> <button aria-label="Copy the bibtex to the clipboard"> <iconify-icon icon="file-icons:bibtex" width="2em" height="2em"></iconify-icon> </button> </div></td></tr><tr class="Publicationsstyled__Publication-sc-997srn-2 IxZzp"><td><div aria-label="Team" style="width:32px;height:32px;background:conic-gradient(#e41a1c 0deg 180deg, #984ea3 180deg 360deg);border-radius:5px"></div></td><td><span><a>Stéphane Guinard</a><a href="https://cv.archives-ouvertes.fr/loic-landrieu">Loic Landrieu</a><a href="https://cv.archives-ouvertes.fr/bruno-vallet">Bruno Vallet</a></span><a href="https://hal.science/hal-01866620">Pré-segmentation pour la classification faiblement supervisée de scènes urbaines à partir de nuages de points 3D LIDAR. </a><span><i>ORASIS 2017</i>, GREYC, Jun 2017, Colleville-sur-Mer, France</span></td><td></td><td></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://hal.science/hal-01866620/document" aria-label="Main document in HAL"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 64C0 28.7 28.7 0 64 0L224 0l0 128c0 17.7 14.3 32 32 32l128 0 0 144-208 0c-35.3 0-64 28.7-64 64l0 144-48 0c-35.3 0-64-28.7-64-64L0 64zm384 64l-128 0L256 0 384 128zM176 352l32 0c30.9 0 56 25.1 56 56s-25.1 56-56 56l-16 0 0 32c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-48 0-80c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24l-16 0 0 48 16 0zm96-80l32 0c26.5 0 48 21.5 48 48l0 64c0 26.5-21.5 48-48 48l-32 0c-8.8 0-16-7.2-16-16l0-128c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16l0-64c0-8.8-7.2-16-16-16l-16 0 0 96 16 0zm80-112c0-8.8 7.2-16 16-16l48 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 32 32 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 48c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-64 0-64z"></path></svg></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"> <button aria-label="Copy the bibtex to the clipboard"> <iconify-icon icon="file-icons:bibtex" width="2em" height="2em"></iconify-icon> </button> </div></td></tr><tr class="Publicationsstyled__Publication-sc-997srn-2 IxZzp"><td><div aria-label="Team" style="width:32px;height:32px;background:conic-gradient(#984ea3 0deg 360deg);border-radius:5px"></div></td><td><span><a href="https://cv.archives-ouvertes.fr/loic-landrieu">Loic Landrieu</a><a href="https://cv.archives-ouvertes.fr/clement-mallet">Clément Mallet</a><a>Martin Weinmann</a></span><a href="https://hal.science/hal-01500777">Comparison of belief propagation and graph-cut approaches for contextual classification of 3D lidar point cloud data. </a><span><i>2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)</i>, Jul 2017, Fort Worth, United States</span></td><td></td><td></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://hal.science/hal-01500777/document" aria-label="Main document in HAL"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 64C0 28.7 28.7 0 64 0L224 0l0 128c0 17.7 14.3 32 32 32l128 0 0 144-208 0c-35.3 0-64 28.7-64 64l0 144-48 0c-35.3 0-64-28.7-64-64L0 64zm384 64l-128 0L256 0 384 128zM176 352l32 0c30.9 0 56 25.1 56 56s-25.1 56-56 56l-16 0 0 32c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-48 0-80c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24l-16 0 0 48 16 0zm96-80l32 0c26.5 0 48 21.5 48 48l0 64c0 26.5-21.5 48-48 48l-32 0c-8.8 0-16-7.2-16-16l0-128c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16l0-64c0-8.8-7.2-16-16-16l-16 0 0 96 16 0zm80-112c0-8.8 7.2-16 16-16l48 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 32 32 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 48c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-64 0-64z"></path></svg></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"> <button aria-label="Copy the bibtex to the clipboard"> <iconify-icon icon="file-icons:bibtex" width="2em" height="2em"></iconify-icon> </button> </div></td></tr></tbody></table></div><div id="pubAP"><h2> <!-- -->Reports or preprints<!-- --> </h2><table class="Publicationsstyled__StyledPublicationList-sc-997srn-1 bJhdgp"><thead></thead><tbody><tr class="Publicationsstyled__Publication-sc-997srn-2 IxZzp"><td><div aria-label="Team" style="width:32px;height:32px;background:conic-gradient(#e41a1c 0deg 180deg, #984ea3 180deg 360deg);border-radius:5px"></div></td><td><span><a href="https://cv.archives-ouvertes.fr/raphael-sulzer">R. Sulzer</a><a href="https://cv.archives-ouvertes.fr/loic-landrieu">Loic Landrieu</a><a href="https://cv.archives-ouvertes.fr/renaud-marlet">Renaud Marlet</a><a href="https://cv.archives-ouvertes.fr/bruno-vallet">Bruno Vallet</a></span><a href="https://hal.science/hal-03968453">A Survey and Benchmark of Automatic Surface Reconstruction from Point Clouds. </a><span>2023</span></td><td></td><td></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://hal.science/hal-03968453/document" aria-label="Main document in HAL"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 64C0 28.7 28.7 0 64 0L224 0l0 128c0 17.7 14.3 32 32 32l128 0 0 144-208 0c-35.3 0-64 28.7-64 64l0 144-48 0c-35.3 0-64-28.7-64-64L0 64zm384 64l-128 0L256 0 384 128zM176 352l32 0c30.9 0 56 25.1 56 56s-25.1 56-56 56l-16 0 0 32c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-48 0-80c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24l-16 0 0 48 16 0zm96-80l32 0c26.5 0 48 21.5 48 48l0 64c0 26.5-21.5 48-48 48l-32 0c-8.8 0-16-7.2-16-16l0-128c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16l0-64c0-8.8-7.2-16-16-16l-16 0 0 96 16 0zm80-112c0-8.8 7.2-16 16-16l48 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 32 32 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 48c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-64 0-64z"></path></svg></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"> <button aria-label="Copy the bibtex to the clipboard"> <iconify-icon icon="file-icons:bibtex" width="2em" height="2em"></iconify-icon> </button> </div></td></tr><tr class="Publicationsstyled__Publication-sc-997srn-2 IxZzp"><td><div aria-label="Team" style="width:32px;height:32px;background:conic-gradient(#984ea3 0deg 360deg);border-radius:5px"></div></td><td><span><a href="https://cv.archives-ouvertes.fr/sebastien-giordano">Sébastien Giordano</a><a>Simon Bailly</a><a href="https://cv.archives-ouvertes.fr/loic-landrieu">Loic Landrieu</a><a href="https://cv.archives-ouvertes.fr/nesrine-chehata">Nesrine Chehata</a></span><a href="https://hal.science/hal-01844619">Temporal Structured Classification of Sentinel 1 and 2 Time Series for Crop Type Mapping. </a><span>2018</span></td><td></td><td></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://hal.science/hal-01844619/document" aria-label="Main document in HAL"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 64C0 28.7 28.7 0 64 0L224 0l0 128c0 17.7 14.3 32 32 32l128 0 0 144-208 0c-35.3 0-64 28.7-64 64l0 144-48 0c-35.3 0-64-28.7-64-64L0 64zm384 64l-128 0L256 0 384 128zM176 352l32 0c30.9 0 56 25.1 56 56s-25.1 56-56 56l-16 0 0 32c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-48 0-80c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24l-16 0 0 48 16 0zm96-80l32 0c26.5 0 48 21.5 48 48l0 64c0 26.5-21.5 48-48 48l-32 0c-8.8 0-16-7.2-16-16l0-128c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16l0-64c0-8.8-7.2-16-16-16l-16 0 0 96 16 0zm80-112c0-8.8 7.2-16 16-16l48 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 32 32 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 48c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-64 0-64z"></path></svg></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"> <button aria-label="Copy the bibtex to the clipboard"> <iconify-icon icon="file-icons:bibtex" width="2em" height="2em"></iconify-icon> </button> </div></td></tr><tr class="Publicationsstyled__Publication-sc-997srn-2 IxZzp"><td><div aria-label="Team" style="width:32px;height:32px;background:conic-gradient(#e41a1c 0deg 180deg, #984ea3 180deg 360deg);border-radius:5px"></div></td><td><span><a href="https://cv.archives-ouvertes.fr/stephane-guinard">Stéphane Guinard</a><a href="https://cv.archives-ouvertes.fr/loic-landrieu">Loic Landrieu</a><a href="https://cv.archives-ouvertes.fr/bruno-vallet">Bruno Vallet</a></span><a href="https://hal.science/hal-01499571">Pré-segmentation pour la classification faiblement supervisée de scènes urbaines à partir de nuages de points 3D LIDAR,Weakly supervised segmentation-aided classification of urban scenes from 3D LIDAR point clouds. </a><span>2017</span></td><td></td><td></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://hal.science/hal-01499571/document" aria-label="Main document in HAL"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 64C0 28.7 28.7 0 64 0L224 0l0 128c0 17.7 14.3 32 32 32l128 0 0 144-208 0c-35.3 0-64 28.7-64 64l0 144-48 0c-35.3 0-64-28.7-64-64L0 64zm384 64l-128 0L256 0 384 128zM176 352l32 0c30.9 0 56 25.1 56 56s-25.1 56-56 56l-16 0 0 32c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-48 0-80c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24l-16 0 0 48 16 0zm96-80l32 0c26.5 0 48 21.5 48 48l0 64c0 26.5-21.5 48-48 48l-32 0c-8.8 0-16-7.2-16-16l0-128c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16l0-64c0-8.8-7.2-16-16-16l-16 0 0 96 16 0zm80-112c0-8.8 7.2-16 16-16l48 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 32 32 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 48c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-64 0-64z"></path></svg></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"> <button aria-label="Copy the bibtex to the clipboard"> <iconify-icon icon="file-icons:bibtex" width="2em" height="2em"></iconify-icon> </button> </div></td></tr></tbody></table></div><div id="pubTH"><h2> <!-- -->Dissertations (PhD theses and habilitations)<!-- --> </h2><table class="Publicationsstyled__StyledPublicationList-sc-997srn-1 bJhdgp"><thead></thead><tbody><tr class="Publicationsstyled__Publication-sc-997srn-2 IxZzp"><td><div aria-label="Team" style="width:32px;height:32px;background:conic-gradient(#984ea3 0deg 360deg);border-radius:5px"></div></td><td><span><a href="https://cv.archives-ouvertes.fr/loic-landrieu">Loic Landrieu</a></span><a href="https://hal.science/tel-04095452">Structured Learning of Geospatial Data,Apprentissage Structuré de Données Géosaptiales. </a><span>Machine Learning [stat.ML]. Paris-Est Sup, 2023</span></td><td></td><td></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"><a href="https://hal.science/tel-04095452/document" aria-label="Main document in HAL"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 64C0 28.7 28.7 0 64 0L224 0l0 128c0 17.7 14.3 32 32 32l128 0 0 144-208 0c-35.3 0-64 28.7-64 64l0 144-48 0c-35.3 0-64-28.7-64-64L0 64zm384 64l-128 0L256 0 384 128zM176 352l32 0c30.9 0 56 25.1 56 56s-25.1 56-56 56l-16 0 0 32c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-48 0-80c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24l-16 0 0 48 16 0zm96-80l32 0c26.5 0 48 21.5 48 48l0 64c0 26.5-21.5 48-48 48l-32 0c-8.8 0-16-7.2-16-16l0-128c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16l0-64c0-8.8-7.2-16-16-16l-16 0 0 96 16 0zm80-112c0-8.8 7.2-16 16-16l48 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 32 32 0c8.8 0 16 7.2 16 16s-7.2 16-16 16l-32 0 0 48c0 8.8-7.2 16-16 16s-16-7.2-16-16l0-64 0-64z"></path></svg></a></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"> <button aria-label="Copy the bibtex to the clipboard"> <iconify-icon icon="file-icons:bibtex" width="2em" height="2em"></iconify-icon> </button> </div></td></tr></tbody></table></div><div id="pubOTHER"><h2> <!-- -->Other publication<!-- --> </h2><table class="Publicationsstyled__StyledPublicationList-sc-997srn-1 bJhdgp"><thead></thead><tbody><tr class="Publicationsstyled__Publication-sc-997srn-2 IxZzp"><td><div aria-label="Team" style="width:32px;height:32px;background:conic-gradient(#984ea3 0deg 360deg);border-radius:5px"></div></td><td><span><a>Ekaterina Kalinicheva</a><a href="https://cv.archives-ouvertes.fr/clement-mallet">Clément Mallet</a><a href="https://cv.archives-ouvertes.fr/loic-landrieu">Loic Landrieu</a><a href="https://cv.archives-ouvertes.fr/nesrine-chehata">Nesrine Chehata</a></span><a href="https://hal.science/hal-03983141">Vegetation Stratum Occupancy Prediction from Airborne LiDAR 3D Point Clouds. </a><span><i>SilviLaser</i>, Sep 2021, Vienne (AUT), Austria. pp.41-43</span></td><td></td><td></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"></div></td><td><div class="Publicationsstyled__ImageLink-sc-997srn-3 ccodOT"> <button aria-label="Copy the bibtex to the clipboard"> <iconify-icon icon="file-icons:bibtex" width="2em" height="2em"></iconify-icon> </button> </div></td></tr></tbody></table></div></div></div></div></main><footer class="Footerstyled__Footer-sc-r3nxg5-0 gqtEdE"><div class="Containerstyled__HorizontalContainer-sc-1u2w6cg-2 bPuwMk"><section><div><div class="Dropdownstyled__Button-sc-5ucibi-1 kcvdpX"><a href="/access/"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 384 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M384 192c0 87.4-117 243-168.3 307.2c-12.3 15.3-35.1 15.3-47.4 0C117 435 0 279.4 0 192C0 86 86 0 192 0S384 86 384 192z"></path></svg> <!-- -->Access &amp; Contact</a></div></div></section><section><div><div class="Dropdownstyled__Button-sc-5ucibi-1 kcvdpX"><a href="https://github.com/umrlastig/umrlastig.github.io"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg> <!-- -->Source</a></div><label>Deployed on 1/20/2026</label></div></section><section><div><div class="Dropdownstyled__Button-sc-5ucibi-1 kcvdpX"><a href="https://www.linkedin.com/search/results/all/?keywords=%23lastig&amp;origin=HASH_TAG_FROM_FEED&amp;sid=RuS"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg> Linkedin</a></div><div class="Dropdownstyled__Button-sc-5ucibi-1 kcvdpX"><a href="https://www.youtube.com/channel/UCpVokwKUh9S4pqZ4cd-GTCQ"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 576 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"></path></svg> YouTube</a></div><div class="Dropdownstyled__Button-sc-5ucibi-1 kcvdpX"><a href="https://github.com/umrlastig"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg> GitHub</a></div></div></section></div><div class="Containerstyled__HorizontalCenteredContainer-sc-1u2w6cg-3 ohOHN"><a href="https://www.univ-gustave-eiffel.fr"><img src="https://www.univ-gustave-eiffel.fr/fileadmin/logo_eiffel_white.svg" style="width:auto;height:30px;filter:invert(1)" alt="Université Gustave Eiffel"/></a><a href="https://geodata-paris.fr"><img src="https://geodata-paris.fr/files/ensg/styles/thumbnail/public/2025-10/G%C3%A9odata_Paris_logo.png" style="width:auto;height:30px" alt="Géodata Paris"/></a><a href="https://www.eivp-paris.fr/"><img src="https://www.univ-gustave-eiffel.fr/fileadmin/_processed_/2/6/csm_EIVP-footer-logo_dd40d6347f.png" style="width:auto;height:60px;filter:invert(1)" alt="EIVP"/></a></div></footer></div></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/members/Loic-Landrieu/";/*]]>*/</script><!-- slice-start id="_gatsby-scripts-1" -->
          <script
            id="gatsby-chunk-mapping"
          >
            window.___chunkMapping="{\"app\":[\"/app-0f346235a37bd7cd201a.js\"],\"component---src-pages-404-js\":[\"/component---src-pages-404-js-45ca354d7457a1b12d7a.js\"],\"component---src-pages-join-index-js\":[\"/component---src-pages-join-index-js-1898960fd1f19bf8dae5.js\"],\"component---src-pages-mdx-frontmatter-slug-js-content-file-path-pages-access-index-fr-mdx\":[\"/component---src-pages-mdx-frontmatter-slug-js-content-file-path-pages-access-index-fr-mdx-26aaa6cf85d2537e5793.js\"],\"component---src-pages-mdx-frontmatter-slug-js-content-file-path-pages-access-index-mdx\":[\"/component---src-pages-mdx-frontmatter-slug-js-content-file-path-pages-access-index-mdx-feab72f780dea34da481.js\"],\"component---src-pages-mdx-frontmatter-slug-js-content-file-path-pages-history-index-fr-mdx\":[\"/component---src-pages-mdx-frontmatter-slug-js-content-file-path-pages-history-index-fr-mdx-bdc80e1b6a23955f6013.js\"],\"component---src-pages-mdx-frontmatter-slug-js-content-file-path-pages-history-index-mdx\":[\"/component---src-pages-mdx-frontmatter-slug-js-content-file-path-pages-history-index-mdx-488d4dedf025b229bd59.js\"],\"component---src-pages-mdx-frontmatter-slug-js-content-file-path-pages-home-index-fr-mdx\":[\"/component---src-pages-mdx-frontmatter-slug-js-content-file-path-pages-home-index-fr-mdx-cf1589fba4bf0a8717fd.js\"],\"component---src-pages-mdx-frontmatter-slug-js-content-file-path-pages-home-index-mdx\":[\"/component---src-pages-mdx-frontmatter-slug-js-content-file-path-pages-home-index-mdx-e84df669325e76467cbc.js\"],\"component---src-pages-mdx-frontmatter-slug-js-content-file-path-pages-legal-index-fr-mdx\":[\"/component---src-pages-mdx-frontmatter-slug-js-content-file-path-pages-legal-index-fr-mdx-3e1f2a30d2872a80f151.js\"],\"component---src-pages-mdx-frontmatter-slug-js-content-file-path-pages-legal-index-mdx\":[\"/component---src-pages-mdx-frontmatter-slug-js-content-file-path-pages-legal-index-mdx-bd9efbe9c6f93d1f0c20.js\"],\"component---src-pages-mdx-frontmatter-slug-js-content-file-path-pages-presentation-index-fr-mdx\":[\"/component---src-pages-mdx-frontmatter-slug-js-content-file-path-pages-presentation-index-fr-mdx-41b141d8bff3168dd171.js\"],\"component---src-pages-mdx-frontmatter-slug-js-content-file-path-pages-presentation-index-mdx\":[\"/component---src-pages-mdx-frontmatter-slug-js-content-file-path-pages-presentation-index-mdx-a173e07914e931267c00.js\"],\"component---src-pages-mdx-frontmatter-slug-js-content-file-path-pages-research-bibliometry-index-fr-mdx\":[\"/component---src-pages-mdx-frontmatter-slug-js-content-file-path-pages-research-bibliometry-index-fr-mdx-c16d2e9b118b7eebffb7.js\"],\"component---src-pages-mdx-frontmatter-slug-js-content-file-path-pages-research-bibliometry-index-mdx\":[\"/component---src-pages-mdx-frontmatter-slug-js-content-file-path-pages-research-bibliometry-index-mdx-8a8949c63f5bc6de3498.js\"],\"component---src-pages-mdx-frontmatter-slug-js-content-file-path-pages-teams-acte-index-fr-mdx\":[\"/component---src-pages-mdx-frontmatter-slug-js-content-file-path-pages-teams-acte-index-fr-mdx-c4c83f03e4361d43083f.js\"],\"component---src-pages-mdx-frontmatter-slug-js-content-file-path-pages-teams-acte-index-mdx\":[\"/component---src-pages-mdx-frontmatter-slug-js-content-file-path-pages-teams-acte-index-mdx-0634c0f164146d6780f3.js\"],\"component---src-pages-mdx-frontmatter-slug-js-content-file-path-pages-teams-geovis-index-fr-mdx\":[\"/component---src-pages-mdx-frontmatter-slug-js-content-file-path-pages-teams-geovis-index-fr-mdx-164aaebb45a98c14a1e9.js\"],\"component---src-pages-mdx-frontmatter-slug-js-content-file-path-pages-teams-geovis-index-mdx\":[\"/component---src-pages-mdx-frontmatter-slug-js-content-file-path-pages-teams-geovis-index-mdx-85763b90ce209eef2371.js\"],\"component---src-pages-mdx-frontmatter-slug-js-content-file-path-pages-teams-index-fr-mdx\":[\"/component---src-pages-mdx-frontmatter-slug-js-content-file-path-pages-teams-index-fr-mdx-be439973bb0be76488c5.js\"],\"component---src-pages-mdx-frontmatter-slug-js-content-file-path-pages-teams-index-mdx\":[\"/component---src-pages-mdx-frontmatter-slug-js-content-file-path-pages-teams-index-mdx-f26f84ec6ba23ba85630.js\"],\"component---src-pages-mdx-frontmatter-slug-js-content-file-path-pages-teams-meig-index-fr-mdx\":[\"/component---src-pages-mdx-frontmatter-slug-js-content-file-path-pages-teams-meig-index-fr-mdx-e34172a0845a94eb2aa3.js\"],\"component---src-pages-mdx-frontmatter-slug-js-content-file-path-pages-teams-meig-index-mdx\":[\"/component---src-pages-mdx-frontmatter-slug-js-content-file-path-pages-teams-meig-index-mdx-99661dcca89d9ad795e8.js\"],\"component---src-pages-mdx-frontmatter-slug-js-content-file-path-pages-teams-strudel-index-fr-mdx\":[\"/component---src-pages-mdx-frontmatter-slug-js-content-file-path-pages-teams-strudel-index-fr-mdx-d878822ad492142404ac.js\"],\"component---src-pages-mdx-frontmatter-slug-js-content-file-path-pages-teams-strudel-index-mdx\":[\"/component---src-pages-mdx-frontmatter-slug-js-content-file-path-pages-teams-strudel-index-mdx-bae7401a9ffe96ad7c2d.js\"],\"component---src-templates-datasets-js\":[\"/component---src-templates-datasets-js-4c32583a400a16630f96.js\"],\"component---src-templates-member-page-js\":[\"/component---src-templates-member-page-js-69721136bcde61597429.js\"],\"component---src-templates-members-js\":[\"/component---src-templates-members-js-5c8f1d97f371730cbd5c.js\"],\"component---src-templates-projects-js\":[\"/component---src-templates-projects-js-0b9952e43da7041a34d9.js\"],\"component---src-templates-publications-js\":[\"/component---src-templates-publications-js-30387c701ead7d4b8e98.js\"],\"component---src-templates-softwares-js\":[\"/component---src-templates-softwares-js-274e2e6fbf7e23d269e9.js\"],\"component---src-templates-theses-js\":[\"/component---src-templates-theses-js-5e3847f81f5bbd8e930a.js\"]}";
          </script>
        <script>window.___webpackCompilationHash="2fb932c27afe3811e3df";</script><script src="/webpack-runtime-2412c341228ebfed5972.js" async></script><script src="/framework-de33ef3c70232d7ecb4e.js" async></script><script src="/app-0f346235a37bd7cd201a.js" async></script><!-- slice-end id="_gatsby-scripts-1" --></body></html>